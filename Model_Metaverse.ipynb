{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Metaverse.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BCBf7EEddLZ",
        "outputId": "f7887449-a18c-4309-9f96-e4068d43c72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel('/content/gdrive/MyDrive/Total Datasets/incident_month.xlsx')"
      ],
      "metadata": {
        "id": "IthYMBWldwu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "0HHBUkoReeJ_",
        "outputId": "dbe39231-067b-4580-8593-68fc81af872b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0   Abs PM  Duration (mins)  Agg_Occ_min  Agg_Occ_max  \\\n",
              "0             0   78.461                2       0.0833       0.1001   \n",
              "1             1    7.645                2       0.3258       0.3447   \n",
              "2             2   32.500                2       0.1494       0.1628   \n",
              "3             3   10.075               12       0.3094       0.3366   \n",
              "4             4   94.876               11       0.0681       0.0715   \n",
              "..          ...      ...              ...          ...          ...   \n",
              "874         874   86.670                0       0.0391       0.0430   \n",
              "875         875    8.145                3       0.0862       0.0987   \n",
              "876         876    8.145               43       0.0826       0.0923   \n",
              "877         877   10.075                2       0.0823       0.0856   \n",
              "878         878  194.303               18       0.0149       0.0209   \n",
              "\n",
              "     Agg_Occ_mean  Agg_Occ_std  Agg_Speed_min  Agg_Speed_max  Agg_Speed_mean  \\\n",
              "0        0.089563     0.006311           64.5           68.4       66.187500   \n",
              "1        0.335989     0.007217           20.4           21.1       20.766667   \n",
              "2        0.157388     0.004639           35.6           40.1       38.662500   \n",
              "3        0.320700     0.008605           20.2           22.9       21.630000   \n",
              "4        0.069890     0.001016           62.9           63.5       63.230000   \n",
              "..            ...          ...            ...            ...             ...   \n",
              "874      0.040725     0.001265           62.8           63.1       62.937500   \n",
              "875      0.092033     0.004455           66.6           67.5       67.155556   \n",
              "876      0.086100     0.002583           66.8           67.8       67.162500   \n",
              "877      0.084022     0.001245           67.5           68.9       67.811111   \n",
              "878      0.017927     0.002104           65.1           65.2       65.181818   \n",
              "\n",
              "     Agg_Speed_std  Agg_Flow_min  Agg_Flow_max  Agg_Flow_mean  Agg_Flow_std  \\\n",
              "0         1.692367         340.0         398.0     366.125000     18.795421   \n",
              "1         0.269258         443.0         462.0     449.888889      6.845518   \n",
              "2         1.581082         444.0         469.0     458.875000      8.322731   \n",
              "3         0.905600         453.0         481.0     468.700000     10.509784   \n",
              "4         0.188856         260.0         277.0     270.100000      5.173651   \n",
              "..             ...           ...           ...            ...           ...   \n",
              "874       0.106066         139.0         155.0     146.125000      5.194434   \n",
              "875       0.332081         455.0         505.0     479.333333     17.109939   \n",
              "876       0.318067         433.0         481.0     453.437500     12.951030   \n",
              "877       0.518277         432.0         451.0     442.666667      7.245688   \n",
              "878       0.040452          25.0          37.0      31.181818      4.045199   \n",
              "\n",
              "     Agg_Delay_min  Agg_Delay_max  Agg_Delay_mean  Agg_Delay_std  \n",
              "0             0.00           0.00        0.000000       0.000000  \n",
              "1            91.15          94.37       92.644444       0.957981  \n",
              "2            19.96          26.78       22.346250       2.296282  \n",
              "3            81.82          93.72       87.404000       3.813348  \n",
              "4             0.00           0.00        0.000000       0.000000  \n",
              "..             ...            ...             ...            ...  \n",
              "874           0.00           0.00        0.000000       0.000000  \n",
              "875           0.00           0.00        0.000000       0.000000  \n",
              "876           0.00           0.00        0.000000       0.000000  \n",
              "877           0.00           0.00        0.000000       0.000000  \n",
              "878           0.00           0.00        0.000000       0.000000  \n",
              "\n",
              "[879 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d672adfa-9184-4a64-90fb-b1aae52ad9d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Abs PM</th>\n",
              "      <th>Duration (mins)</th>\n",
              "      <th>Agg_Occ_min</th>\n",
              "      <th>Agg_Occ_max</th>\n",
              "      <th>Agg_Occ_mean</th>\n",
              "      <th>Agg_Occ_std</th>\n",
              "      <th>Agg_Speed_min</th>\n",
              "      <th>Agg_Speed_max</th>\n",
              "      <th>Agg_Speed_mean</th>\n",
              "      <th>Agg_Speed_std</th>\n",
              "      <th>Agg_Flow_min</th>\n",
              "      <th>Agg_Flow_max</th>\n",
              "      <th>Agg_Flow_mean</th>\n",
              "      <th>Agg_Flow_std</th>\n",
              "      <th>Agg_Delay_min</th>\n",
              "      <th>Agg_Delay_max</th>\n",
              "      <th>Agg_Delay_mean</th>\n",
              "      <th>Agg_Delay_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>78.461</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>0.1001</td>\n",
              "      <td>0.089563</td>\n",
              "      <td>0.006311</td>\n",
              "      <td>64.5</td>\n",
              "      <td>68.4</td>\n",
              "      <td>66.187500</td>\n",
              "      <td>1.692367</td>\n",
              "      <td>340.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>366.125000</td>\n",
              "      <td>18.795421</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7.645</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3258</td>\n",
              "      <td>0.3447</td>\n",
              "      <td>0.335989</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>20.4</td>\n",
              "      <td>21.1</td>\n",
              "      <td>20.766667</td>\n",
              "      <td>0.269258</td>\n",
              "      <td>443.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>449.888889</td>\n",
              "      <td>6.845518</td>\n",
              "      <td>91.15</td>\n",
              "      <td>94.37</td>\n",
              "      <td>92.644444</td>\n",
              "      <td>0.957981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>32.500</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1494</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.157388</td>\n",
              "      <td>0.004639</td>\n",
              "      <td>35.6</td>\n",
              "      <td>40.1</td>\n",
              "      <td>38.662500</td>\n",
              "      <td>1.581082</td>\n",
              "      <td>444.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>458.875000</td>\n",
              "      <td>8.322731</td>\n",
              "      <td>19.96</td>\n",
              "      <td>26.78</td>\n",
              "      <td>22.346250</td>\n",
              "      <td>2.296282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10.075</td>\n",
              "      <td>12</td>\n",
              "      <td>0.3094</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.320700</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.630000</td>\n",
              "      <td>0.905600</td>\n",
              "      <td>453.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>468.700000</td>\n",
              "      <td>10.509784</td>\n",
              "      <td>81.82</td>\n",
              "      <td>93.72</td>\n",
              "      <td>87.404000</td>\n",
              "      <td>3.813348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>94.876</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.069890</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>62.9</td>\n",
              "      <td>63.5</td>\n",
              "      <td>63.230000</td>\n",
              "      <td>0.188856</td>\n",
              "      <td>260.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>270.100000</td>\n",
              "      <td>5.173651</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>874</td>\n",
              "      <td>86.670</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0391</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>62.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>62.937500</td>\n",
              "      <td>0.106066</td>\n",
              "      <td>139.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>146.125000</td>\n",
              "      <td>5.194434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>875</td>\n",
              "      <td>8.145</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0862</td>\n",
              "      <td>0.0987</td>\n",
              "      <td>0.092033</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>66.6</td>\n",
              "      <td>67.5</td>\n",
              "      <td>67.155556</td>\n",
              "      <td>0.332081</td>\n",
              "      <td>455.0</td>\n",
              "      <td>505.0</td>\n",
              "      <td>479.333333</td>\n",
              "      <td>17.109939</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>876</td>\n",
              "      <td>8.145</td>\n",
              "      <td>43</td>\n",
              "      <td>0.0826</td>\n",
              "      <td>0.0923</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>66.8</td>\n",
              "      <td>67.8</td>\n",
              "      <td>67.162500</td>\n",
              "      <td>0.318067</td>\n",
              "      <td>433.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>453.437500</td>\n",
              "      <td>12.951030</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>877</td>\n",
              "      <td>10.075</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>0.084022</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>67.5</td>\n",
              "      <td>68.9</td>\n",
              "      <td>67.811111</td>\n",
              "      <td>0.518277</td>\n",
              "      <td>432.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>442.666667</td>\n",
              "      <td>7.245688</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>878</td>\n",
              "      <td>194.303</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>0.0209</td>\n",
              "      <td>0.017927</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>65.1</td>\n",
              "      <td>65.2</td>\n",
              "      <td>65.181818</td>\n",
              "      <td>0.040452</td>\n",
              "      <td>25.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>31.181818</td>\n",
              "      <td>4.045199</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>879 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d672adfa-9184-4a64-90fb-b1aae52ad9d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d672adfa-9184-4a64-90fb-b1aae52ad9d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d672adfa-9184-4a64-90fb-b1aae52ad9d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    print(col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suu6evU6efHd",
        "outputId": "1554b6ee-2406-43ea-f5b7-ce906718bca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0\n",
            "Abs PM\n",
            "Duration (mins)\n",
            "Agg_Occ_min\n",
            "Agg_Occ_max\n",
            "Agg_Occ_mean\n",
            "Agg_Occ_std\n",
            "Agg_Speed_min\n",
            "Agg_Speed_max\n",
            "Agg_Speed_mean\n",
            "Agg_Speed_std\n",
            "Agg_Flow_min\n",
            "Agg_Flow_max\n",
            "Agg_Flow_mean\n",
            "Agg_Flow_std\n",
            "Agg_Delay_min\n",
            "Agg_Delay_max\n",
            "Agg_Delay_mean\n",
            "Agg_Delay_std\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 0'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "h4sz0RLSemL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "u7PW-qmpfE5t",
        "outputId": "2cbd37f2-17f9-4701-b57a-1cedc59ed70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Abs PM  Duration (mins)  Agg_Occ_min  Agg_Occ_max  Agg_Occ_mean  \\\n",
              "0     78.461                2       0.0833       0.1001      0.089563   \n",
              "1      7.645                2       0.3258       0.3447      0.335989   \n",
              "2     32.500                2       0.1494       0.1628      0.157388   \n",
              "3     10.075               12       0.3094       0.3366      0.320700   \n",
              "4     94.876               11       0.0681       0.0715      0.069890   \n",
              "..       ...              ...          ...          ...           ...   \n",
              "874   86.670                0       0.0391       0.0430      0.040725   \n",
              "875    8.145                3       0.0862       0.0987      0.092033   \n",
              "876    8.145               43       0.0826       0.0923      0.086100   \n",
              "877   10.075                2       0.0823       0.0856      0.084022   \n",
              "878  194.303               18       0.0149       0.0209      0.017927   \n",
              "\n",
              "     Agg_Occ_std  Agg_Speed_min  Agg_Speed_max  Agg_Speed_mean  Agg_Speed_std  \\\n",
              "0       0.006311           64.5           68.4       66.187500       1.692367   \n",
              "1       0.007217           20.4           21.1       20.766667       0.269258   \n",
              "2       0.004639           35.6           40.1       38.662500       1.581082   \n",
              "3       0.008605           20.2           22.9       21.630000       0.905600   \n",
              "4       0.001016           62.9           63.5       63.230000       0.188856   \n",
              "..           ...            ...            ...             ...            ...   \n",
              "874     0.001265           62.8           63.1       62.937500       0.106066   \n",
              "875     0.004455           66.6           67.5       67.155556       0.332081   \n",
              "876     0.002583           66.8           67.8       67.162500       0.318067   \n",
              "877     0.001245           67.5           68.9       67.811111       0.518277   \n",
              "878     0.002104           65.1           65.2       65.181818       0.040452   \n",
              "\n",
              "     Agg_Flow_min  Agg_Flow_max  Agg_Flow_mean  Agg_Flow_std  Agg_Delay_min  \\\n",
              "0           340.0         398.0     366.125000     18.795421           0.00   \n",
              "1           443.0         462.0     449.888889      6.845518          91.15   \n",
              "2           444.0         469.0     458.875000      8.322731          19.96   \n",
              "3           453.0         481.0     468.700000     10.509784          81.82   \n",
              "4           260.0         277.0     270.100000      5.173651           0.00   \n",
              "..            ...           ...            ...           ...            ...   \n",
              "874         139.0         155.0     146.125000      5.194434           0.00   \n",
              "875         455.0         505.0     479.333333     17.109939           0.00   \n",
              "876         433.0         481.0     453.437500     12.951030           0.00   \n",
              "877         432.0         451.0     442.666667      7.245688           0.00   \n",
              "878          25.0          37.0      31.181818      4.045199           0.00   \n",
              "\n",
              "     Agg_Delay_max  Agg_Delay_mean  Agg_Delay_std  \n",
              "0             0.00        0.000000       0.000000  \n",
              "1            94.37       92.644444       0.957981  \n",
              "2            26.78       22.346250       2.296282  \n",
              "3            93.72       87.404000       3.813348  \n",
              "4             0.00        0.000000       0.000000  \n",
              "..             ...             ...            ...  \n",
              "874           0.00        0.000000       0.000000  \n",
              "875           0.00        0.000000       0.000000  \n",
              "876           0.00        0.000000       0.000000  \n",
              "877           0.00        0.000000       0.000000  \n",
              "878           0.00        0.000000       0.000000  \n",
              "\n",
              "[879 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b20ba78-d23a-4836-be2a-f65a149cbe9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abs PM</th>\n",
              "      <th>Duration (mins)</th>\n",
              "      <th>Agg_Occ_min</th>\n",
              "      <th>Agg_Occ_max</th>\n",
              "      <th>Agg_Occ_mean</th>\n",
              "      <th>Agg_Occ_std</th>\n",
              "      <th>Agg_Speed_min</th>\n",
              "      <th>Agg_Speed_max</th>\n",
              "      <th>Agg_Speed_mean</th>\n",
              "      <th>Agg_Speed_std</th>\n",
              "      <th>Agg_Flow_min</th>\n",
              "      <th>Agg_Flow_max</th>\n",
              "      <th>Agg_Flow_mean</th>\n",
              "      <th>Agg_Flow_std</th>\n",
              "      <th>Agg_Delay_min</th>\n",
              "      <th>Agg_Delay_max</th>\n",
              "      <th>Agg_Delay_mean</th>\n",
              "      <th>Agg_Delay_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.461</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>0.1001</td>\n",
              "      <td>0.089563</td>\n",
              "      <td>0.006311</td>\n",
              "      <td>64.5</td>\n",
              "      <td>68.4</td>\n",
              "      <td>66.187500</td>\n",
              "      <td>1.692367</td>\n",
              "      <td>340.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>366.125000</td>\n",
              "      <td>18.795421</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.645</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3258</td>\n",
              "      <td>0.3447</td>\n",
              "      <td>0.335989</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>20.4</td>\n",
              "      <td>21.1</td>\n",
              "      <td>20.766667</td>\n",
              "      <td>0.269258</td>\n",
              "      <td>443.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>449.888889</td>\n",
              "      <td>6.845518</td>\n",
              "      <td>91.15</td>\n",
              "      <td>94.37</td>\n",
              "      <td>92.644444</td>\n",
              "      <td>0.957981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32.500</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1494</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.157388</td>\n",
              "      <td>0.004639</td>\n",
              "      <td>35.6</td>\n",
              "      <td>40.1</td>\n",
              "      <td>38.662500</td>\n",
              "      <td>1.581082</td>\n",
              "      <td>444.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>458.875000</td>\n",
              "      <td>8.322731</td>\n",
              "      <td>19.96</td>\n",
              "      <td>26.78</td>\n",
              "      <td>22.346250</td>\n",
              "      <td>2.296282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.075</td>\n",
              "      <td>12</td>\n",
              "      <td>0.3094</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.320700</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.630000</td>\n",
              "      <td>0.905600</td>\n",
              "      <td>453.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>468.700000</td>\n",
              "      <td>10.509784</td>\n",
              "      <td>81.82</td>\n",
              "      <td>93.72</td>\n",
              "      <td>87.404000</td>\n",
              "      <td>3.813348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.876</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.069890</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>62.9</td>\n",
              "      <td>63.5</td>\n",
              "      <td>63.230000</td>\n",
              "      <td>0.188856</td>\n",
              "      <td>260.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>270.100000</td>\n",
              "      <td>5.173651</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>86.670</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0391</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>62.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>62.937500</td>\n",
              "      <td>0.106066</td>\n",
              "      <td>139.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>146.125000</td>\n",
              "      <td>5.194434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>8.145</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0862</td>\n",
              "      <td>0.0987</td>\n",
              "      <td>0.092033</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>66.6</td>\n",
              "      <td>67.5</td>\n",
              "      <td>67.155556</td>\n",
              "      <td>0.332081</td>\n",
              "      <td>455.0</td>\n",
              "      <td>505.0</td>\n",
              "      <td>479.333333</td>\n",
              "      <td>17.109939</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>8.145</td>\n",
              "      <td>43</td>\n",
              "      <td>0.0826</td>\n",
              "      <td>0.0923</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>66.8</td>\n",
              "      <td>67.8</td>\n",
              "      <td>67.162500</td>\n",
              "      <td>0.318067</td>\n",
              "      <td>433.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>453.437500</td>\n",
              "      <td>12.951030</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>10.075</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>0.084022</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>67.5</td>\n",
              "      <td>68.9</td>\n",
              "      <td>67.811111</td>\n",
              "      <td>0.518277</td>\n",
              "      <td>432.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>442.666667</td>\n",
              "      <td>7.245688</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>194.303</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>0.0209</td>\n",
              "      <td>0.017927</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>65.1</td>\n",
              "      <td>65.2</td>\n",
              "      <td>65.181818</td>\n",
              "      <td>0.040452</td>\n",
              "      <td>25.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>31.181818</td>\n",
              "      <td>4.045199</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>879 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b20ba78-d23a-4836-be2a-f65a149cbe9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b20ba78-d23a-4836-be2a-f65a149cbe9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b20ba78-d23a-4836-be2a-f65a149cbe9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.dropna()"
      ],
      "metadata": {
        "id": "Lf9HSgcXm8Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "_mcgqL_bnjmF",
        "outputId": "8abc5adc-7d34-4d77-9810-2f60f217c591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Abs PM  Duration (mins)  Agg_Occ_min  Agg_Occ_max  Agg_Occ_mean  \\\n",
              "0     78.461                2       0.0833       0.1001      0.089563   \n",
              "1      7.645                2       0.3258       0.3447      0.335989   \n",
              "2     32.500                2       0.1494       0.1628      0.157388   \n",
              "3     10.075               12       0.3094       0.3366      0.320700   \n",
              "4     94.876               11       0.0681       0.0715      0.069890   \n",
              "..       ...              ...          ...          ...           ...   \n",
              "874   86.670                0       0.0391       0.0430      0.040725   \n",
              "875    8.145                3       0.0862       0.0987      0.092033   \n",
              "876    8.145               43       0.0826       0.0923      0.086100   \n",
              "877   10.075                2       0.0823       0.0856      0.084022   \n",
              "878  194.303               18       0.0149       0.0209      0.017927   \n",
              "\n",
              "     Agg_Occ_std  Agg_Speed_min  Agg_Speed_max  Agg_Speed_mean  Agg_Speed_std  \\\n",
              "0       0.006311           64.5           68.4       66.187500       1.692367   \n",
              "1       0.007217           20.4           21.1       20.766667       0.269258   \n",
              "2       0.004639           35.6           40.1       38.662500       1.581082   \n",
              "3       0.008605           20.2           22.9       21.630000       0.905600   \n",
              "4       0.001016           62.9           63.5       63.230000       0.188856   \n",
              "..           ...            ...            ...             ...            ...   \n",
              "874     0.001265           62.8           63.1       62.937500       0.106066   \n",
              "875     0.004455           66.6           67.5       67.155556       0.332081   \n",
              "876     0.002583           66.8           67.8       67.162500       0.318067   \n",
              "877     0.001245           67.5           68.9       67.811111       0.518277   \n",
              "878     0.002104           65.1           65.2       65.181818       0.040452   \n",
              "\n",
              "     Agg_Flow_min  Agg_Flow_max  Agg_Flow_mean  Agg_Flow_std  Agg_Delay_min  \\\n",
              "0           340.0         398.0     366.125000     18.795421           0.00   \n",
              "1           443.0         462.0     449.888889      6.845518          91.15   \n",
              "2           444.0         469.0     458.875000      8.322731          19.96   \n",
              "3           453.0         481.0     468.700000     10.509784          81.82   \n",
              "4           260.0         277.0     270.100000      5.173651           0.00   \n",
              "..            ...           ...            ...           ...            ...   \n",
              "874         139.0         155.0     146.125000      5.194434           0.00   \n",
              "875         455.0         505.0     479.333333     17.109939           0.00   \n",
              "876         433.0         481.0     453.437500     12.951030           0.00   \n",
              "877         432.0         451.0     442.666667      7.245688           0.00   \n",
              "878          25.0          37.0      31.181818      4.045199           0.00   \n",
              "\n",
              "     Agg_Delay_max  Agg_Delay_mean  Agg_Delay_std  \n",
              "0             0.00        0.000000       0.000000  \n",
              "1            94.37       92.644444       0.957981  \n",
              "2            26.78       22.346250       2.296282  \n",
              "3            93.72       87.404000       3.813348  \n",
              "4             0.00        0.000000       0.000000  \n",
              "..             ...             ...            ...  \n",
              "874           0.00        0.000000       0.000000  \n",
              "875           0.00        0.000000       0.000000  \n",
              "876           0.00        0.000000       0.000000  \n",
              "877           0.00        0.000000       0.000000  \n",
              "878           0.00        0.000000       0.000000  \n",
              "\n",
              "[850 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b92f8444-dd2b-4b7f-a74f-9a3ff06c4f8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abs PM</th>\n",
              "      <th>Duration (mins)</th>\n",
              "      <th>Agg_Occ_min</th>\n",
              "      <th>Agg_Occ_max</th>\n",
              "      <th>Agg_Occ_mean</th>\n",
              "      <th>Agg_Occ_std</th>\n",
              "      <th>Agg_Speed_min</th>\n",
              "      <th>Agg_Speed_max</th>\n",
              "      <th>Agg_Speed_mean</th>\n",
              "      <th>Agg_Speed_std</th>\n",
              "      <th>Agg_Flow_min</th>\n",
              "      <th>Agg_Flow_max</th>\n",
              "      <th>Agg_Flow_mean</th>\n",
              "      <th>Agg_Flow_std</th>\n",
              "      <th>Agg_Delay_min</th>\n",
              "      <th>Agg_Delay_max</th>\n",
              "      <th>Agg_Delay_mean</th>\n",
              "      <th>Agg_Delay_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.461</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>0.1001</td>\n",
              "      <td>0.089563</td>\n",
              "      <td>0.006311</td>\n",
              "      <td>64.5</td>\n",
              "      <td>68.4</td>\n",
              "      <td>66.187500</td>\n",
              "      <td>1.692367</td>\n",
              "      <td>340.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>366.125000</td>\n",
              "      <td>18.795421</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.645</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3258</td>\n",
              "      <td>0.3447</td>\n",
              "      <td>0.335989</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>20.4</td>\n",
              "      <td>21.1</td>\n",
              "      <td>20.766667</td>\n",
              "      <td>0.269258</td>\n",
              "      <td>443.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>449.888889</td>\n",
              "      <td>6.845518</td>\n",
              "      <td>91.15</td>\n",
              "      <td>94.37</td>\n",
              "      <td>92.644444</td>\n",
              "      <td>0.957981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32.500</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1494</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.157388</td>\n",
              "      <td>0.004639</td>\n",
              "      <td>35.6</td>\n",
              "      <td>40.1</td>\n",
              "      <td>38.662500</td>\n",
              "      <td>1.581082</td>\n",
              "      <td>444.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>458.875000</td>\n",
              "      <td>8.322731</td>\n",
              "      <td>19.96</td>\n",
              "      <td>26.78</td>\n",
              "      <td>22.346250</td>\n",
              "      <td>2.296282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.075</td>\n",
              "      <td>12</td>\n",
              "      <td>0.3094</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.320700</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.630000</td>\n",
              "      <td>0.905600</td>\n",
              "      <td>453.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>468.700000</td>\n",
              "      <td>10.509784</td>\n",
              "      <td>81.82</td>\n",
              "      <td>93.72</td>\n",
              "      <td>87.404000</td>\n",
              "      <td>3.813348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.876</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.069890</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>62.9</td>\n",
              "      <td>63.5</td>\n",
              "      <td>63.230000</td>\n",
              "      <td>0.188856</td>\n",
              "      <td>260.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>270.100000</td>\n",
              "      <td>5.173651</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>874</th>\n",
              "      <td>86.670</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0391</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>62.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>62.937500</td>\n",
              "      <td>0.106066</td>\n",
              "      <td>139.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>146.125000</td>\n",
              "      <td>5.194434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875</th>\n",
              "      <td>8.145</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0862</td>\n",
              "      <td>0.0987</td>\n",
              "      <td>0.092033</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>66.6</td>\n",
              "      <td>67.5</td>\n",
              "      <td>67.155556</td>\n",
              "      <td>0.332081</td>\n",
              "      <td>455.0</td>\n",
              "      <td>505.0</td>\n",
              "      <td>479.333333</td>\n",
              "      <td>17.109939</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>8.145</td>\n",
              "      <td>43</td>\n",
              "      <td>0.0826</td>\n",
              "      <td>0.0923</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>66.8</td>\n",
              "      <td>67.8</td>\n",
              "      <td>67.162500</td>\n",
              "      <td>0.318067</td>\n",
              "      <td>433.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>453.437500</td>\n",
              "      <td>12.951030</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>10.075</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>0.084022</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>67.5</td>\n",
              "      <td>68.9</td>\n",
              "      <td>67.811111</td>\n",
              "      <td>0.518277</td>\n",
              "      <td>432.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>442.666667</td>\n",
              "      <td>7.245688</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>194.303</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>0.0209</td>\n",
              "      <td>0.017927</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>65.1</td>\n",
              "      <td>65.2</td>\n",
              "      <td>65.181818</td>\n",
              "      <td>0.040452</td>\n",
              "      <td>25.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>31.181818</td>\n",
              "      <td>4.045199</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>850 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b92f8444-dd2b-4b7f-a74f-9a3ff06c4f8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b92f8444-dd2b-4b7f-a74f-9a3ff06c4f8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b92f8444-dd2b-4b7f-a74f-9a3ff06c4f8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.reset_index(inplace = True)"
      ],
      "metadata": {
        "id": "MROt4HAbpHky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df1['Duration (mins)']\n",
        "X = df1.drop(['Duration (mins)'],axis=1)\n"
      ],
      "metadata": {
        "id": "tXrlMRX8fLAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxqNTRP-fZIH",
        "outputId": "5e9c31fa-6fb2-40a9-c652-3d97df0e7c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2\n",
              "1       2\n",
              "2       2\n",
              "3      12\n",
              "4      11\n",
              "       ..\n",
              "845     0\n",
              "846     3\n",
              "847    43\n",
              "848     2\n",
              "849    18\n",
              "Name: Duration (mins), Length: 850, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X = X.drop(['index'],axis = 1,inplace = True)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "40bAhdeGfaEi",
        "outputId": "94cf8c7d-fd23-4165-f6e2-d3dd1ae9da0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index   Abs PM  Agg_Occ_min  Agg_Occ_max  Agg_Occ_mean  Agg_Occ_std  \\\n",
              "0        0   78.461       0.0833       0.1001      0.089563     0.006311   \n",
              "1        1    7.645       0.3258       0.3447      0.335989     0.007217   \n",
              "2        2   32.500       0.1494       0.1628      0.157388     0.004639   \n",
              "3        3   10.075       0.3094       0.3366      0.320700     0.008605   \n",
              "4        4   94.876       0.0681       0.0715      0.069890     0.001016   \n",
              "..     ...      ...          ...          ...           ...          ...   \n",
              "845    874   86.670       0.0391       0.0430      0.040725     0.001265   \n",
              "846    875    8.145       0.0862       0.0987      0.092033     0.004455   \n",
              "847    876    8.145       0.0826       0.0923      0.086100     0.002583   \n",
              "848    877   10.075       0.0823       0.0856      0.084022     0.001245   \n",
              "849    878  194.303       0.0149       0.0209      0.017927     0.002104   \n",
              "\n",
              "     Agg_Speed_min  Agg_Speed_max  Agg_Speed_mean  Agg_Speed_std  \\\n",
              "0             64.5           68.4       66.187500       1.692367   \n",
              "1             20.4           21.1       20.766667       0.269258   \n",
              "2             35.6           40.1       38.662500       1.581082   \n",
              "3             20.2           22.9       21.630000       0.905600   \n",
              "4             62.9           63.5       63.230000       0.188856   \n",
              "..             ...            ...             ...            ...   \n",
              "845           62.8           63.1       62.937500       0.106066   \n",
              "846           66.6           67.5       67.155556       0.332081   \n",
              "847           66.8           67.8       67.162500       0.318067   \n",
              "848           67.5           68.9       67.811111       0.518277   \n",
              "849           65.1           65.2       65.181818       0.040452   \n",
              "\n",
              "     Agg_Flow_min  Agg_Flow_max  Agg_Flow_mean  Agg_Flow_std  Agg_Delay_min  \\\n",
              "0           340.0         398.0     366.125000     18.795421           0.00   \n",
              "1           443.0         462.0     449.888889      6.845518          91.15   \n",
              "2           444.0         469.0     458.875000      8.322731          19.96   \n",
              "3           453.0         481.0     468.700000     10.509784          81.82   \n",
              "4           260.0         277.0     270.100000      5.173651           0.00   \n",
              "..            ...           ...            ...           ...            ...   \n",
              "845         139.0         155.0     146.125000      5.194434           0.00   \n",
              "846         455.0         505.0     479.333333     17.109939           0.00   \n",
              "847         433.0         481.0     453.437500     12.951030           0.00   \n",
              "848         432.0         451.0     442.666667      7.245688           0.00   \n",
              "849          25.0          37.0      31.181818      4.045199           0.00   \n",
              "\n",
              "     Agg_Delay_max  Agg_Delay_mean  Agg_Delay_std  \n",
              "0             0.00        0.000000       0.000000  \n",
              "1            94.37       92.644444       0.957981  \n",
              "2            26.78       22.346250       2.296282  \n",
              "3            93.72       87.404000       3.813348  \n",
              "4             0.00        0.000000       0.000000  \n",
              "..             ...             ...            ...  \n",
              "845           0.00        0.000000       0.000000  \n",
              "846           0.00        0.000000       0.000000  \n",
              "847           0.00        0.000000       0.000000  \n",
              "848           0.00        0.000000       0.000000  \n",
              "849           0.00        0.000000       0.000000  \n",
              "\n",
              "[850 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14420bac-eb4e-4024-8beb-443e3d2e4798\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>Abs PM</th>\n",
              "      <th>Agg_Occ_min</th>\n",
              "      <th>Agg_Occ_max</th>\n",
              "      <th>Agg_Occ_mean</th>\n",
              "      <th>Agg_Occ_std</th>\n",
              "      <th>Agg_Speed_min</th>\n",
              "      <th>Agg_Speed_max</th>\n",
              "      <th>Agg_Speed_mean</th>\n",
              "      <th>Agg_Speed_std</th>\n",
              "      <th>Agg_Flow_min</th>\n",
              "      <th>Agg_Flow_max</th>\n",
              "      <th>Agg_Flow_mean</th>\n",
              "      <th>Agg_Flow_std</th>\n",
              "      <th>Agg_Delay_min</th>\n",
              "      <th>Agg_Delay_max</th>\n",
              "      <th>Agg_Delay_mean</th>\n",
              "      <th>Agg_Delay_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>78.461</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>0.1001</td>\n",
              "      <td>0.089563</td>\n",
              "      <td>0.006311</td>\n",
              "      <td>64.5</td>\n",
              "      <td>68.4</td>\n",
              "      <td>66.187500</td>\n",
              "      <td>1.692367</td>\n",
              "      <td>340.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>366.125000</td>\n",
              "      <td>18.795421</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7.645</td>\n",
              "      <td>0.3258</td>\n",
              "      <td>0.3447</td>\n",
              "      <td>0.335989</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>20.4</td>\n",
              "      <td>21.1</td>\n",
              "      <td>20.766667</td>\n",
              "      <td>0.269258</td>\n",
              "      <td>443.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>449.888889</td>\n",
              "      <td>6.845518</td>\n",
              "      <td>91.15</td>\n",
              "      <td>94.37</td>\n",
              "      <td>92.644444</td>\n",
              "      <td>0.957981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>32.500</td>\n",
              "      <td>0.1494</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.157388</td>\n",
              "      <td>0.004639</td>\n",
              "      <td>35.6</td>\n",
              "      <td>40.1</td>\n",
              "      <td>38.662500</td>\n",
              "      <td>1.581082</td>\n",
              "      <td>444.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>458.875000</td>\n",
              "      <td>8.322731</td>\n",
              "      <td>19.96</td>\n",
              "      <td>26.78</td>\n",
              "      <td>22.346250</td>\n",
              "      <td>2.296282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10.075</td>\n",
              "      <td>0.3094</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.320700</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.630000</td>\n",
              "      <td>0.905600</td>\n",
              "      <td>453.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>468.700000</td>\n",
              "      <td>10.509784</td>\n",
              "      <td>81.82</td>\n",
              "      <td>93.72</td>\n",
              "      <td>87.404000</td>\n",
              "      <td>3.813348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>94.876</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.069890</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>62.9</td>\n",
              "      <td>63.5</td>\n",
              "      <td>63.230000</td>\n",
              "      <td>0.188856</td>\n",
              "      <td>260.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>270.100000</td>\n",
              "      <td>5.173651</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>874</td>\n",
              "      <td>86.670</td>\n",
              "      <td>0.0391</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>62.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>62.937500</td>\n",
              "      <td>0.106066</td>\n",
              "      <td>139.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>146.125000</td>\n",
              "      <td>5.194434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>875</td>\n",
              "      <td>8.145</td>\n",
              "      <td>0.0862</td>\n",
              "      <td>0.0987</td>\n",
              "      <td>0.092033</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>66.6</td>\n",
              "      <td>67.5</td>\n",
              "      <td>67.155556</td>\n",
              "      <td>0.332081</td>\n",
              "      <td>455.0</td>\n",
              "      <td>505.0</td>\n",
              "      <td>479.333333</td>\n",
              "      <td>17.109939</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>876</td>\n",
              "      <td>8.145</td>\n",
              "      <td>0.0826</td>\n",
              "      <td>0.0923</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>66.8</td>\n",
              "      <td>67.8</td>\n",
              "      <td>67.162500</td>\n",
              "      <td>0.318067</td>\n",
              "      <td>433.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>453.437500</td>\n",
              "      <td>12.951030</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>877</td>\n",
              "      <td>10.075</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>0.084022</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>67.5</td>\n",
              "      <td>68.9</td>\n",
              "      <td>67.811111</td>\n",
              "      <td>0.518277</td>\n",
              "      <td>432.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>442.666667</td>\n",
              "      <td>7.245688</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>878</td>\n",
              "      <td>194.303</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>0.0209</td>\n",
              "      <td>0.017927</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>65.1</td>\n",
              "      <td>65.2</td>\n",
              "      <td>65.181818</td>\n",
              "      <td>0.040452</td>\n",
              "      <td>25.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>31.181818</td>\n",
              "      <td>4.045199</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>850 rows × 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14420bac-eb4e-4024-8beb-443e3d2e4798')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14420bac-eb4e-4024-8beb-443e3d2e4798 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14420bac-eb4e-4024-8beb-443e3d2e4798');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = X.drop(['index'],axis = 1)\n",
        "X1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "5XSqhKAipk-E",
        "outputId": "d069ceb9-8b3c-4d0d-b17b-ed808f59c984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Abs PM  Agg_Occ_min  Agg_Occ_max  Agg_Occ_mean  Agg_Occ_std  \\\n",
              "0     78.461       0.0833       0.1001      0.089563     0.006311   \n",
              "1      7.645       0.3258       0.3447      0.335989     0.007217   \n",
              "2     32.500       0.1494       0.1628      0.157388     0.004639   \n",
              "3     10.075       0.3094       0.3366      0.320700     0.008605   \n",
              "4     94.876       0.0681       0.0715      0.069890     0.001016   \n",
              "..       ...          ...          ...           ...          ...   \n",
              "845   86.670       0.0391       0.0430      0.040725     0.001265   \n",
              "846    8.145       0.0862       0.0987      0.092033     0.004455   \n",
              "847    8.145       0.0826       0.0923      0.086100     0.002583   \n",
              "848   10.075       0.0823       0.0856      0.084022     0.001245   \n",
              "849  194.303       0.0149       0.0209      0.017927     0.002104   \n",
              "\n",
              "     Agg_Speed_min  Agg_Speed_max  Agg_Speed_mean  Agg_Speed_std  \\\n",
              "0             64.5           68.4       66.187500       1.692367   \n",
              "1             20.4           21.1       20.766667       0.269258   \n",
              "2             35.6           40.1       38.662500       1.581082   \n",
              "3             20.2           22.9       21.630000       0.905600   \n",
              "4             62.9           63.5       63.230000       0.188856   \n",
              "..             ...            ...             ...            ...   \n",
              "845           62.8           63.1       62.937500       0.106066   \n",
              "846           66.6           67.5       67.155556       0.332081   \n",
              "847           66.8           67.8       67.162500       0.318067   \n",
              "848           67.5           68.9       67.811111       0.518277   \n",
              "849           65.1           65.2       65.181818       0.040452   \n",
              "\n",
              "     Agg_Flow_min  Agg_Flow_max  Agg_Flow_mean  Agg_Flow_std  Agg_Delay_min  \\\n",
              "0           340.0         398.0     366.125000     18.795421           0.00   \n",
              "1           443.0         462.0     449.888889      6.845518          91.15   \n",
              "2           444.0         469.0     458.875000      8.322731          19.96   \n",
              "3           453.0         481.0     468.700000     10.509784          81.82   \n",
              "4           260.0         277.0     270.100000      5.173651           0.00   \n",
              "..            ...           ...            ...           ...            ...   \n",
              "845         139.0         155.0     146.125000      5.194434           0.00   \n",
              "846         455.0         505.0     479.333333     17.109939           0.00   \n",
              "847         433.0         481.0     453.437500     12.951030           0.00   \n",
              "848         432.0         451.0     442.666667      7.245688           0.00   \n",
              "849          25.0          37.0      31.181818      4.045199           0.00   \n",
              "\n",
              "     Agg_Delay_max  Agg_Delay_mean  Agg_Delay_std  \n",
              "0             0.00        0.000000       0.000000  \n",
              "1            94.37       92.644444       0.957981  \n",
              "2            26.78       22.346250       2.296282  \n",
              "3            93.72       87.404000       3.813348  \n",
              "4             0.00        0.000000       0.000000  \n",
              "..             ...             ...            ...  \n",
              "845           0.00        0.000000       0.000000  \n",
              "846           0.00        0.000000       0.000000  \n",
              "847           0.00        0.000000       0.000000  \n",
              "848           0.00        0.000000       0.000000  \n",
              "849           0.00        0.000000       0.000000  \n",
              "\n",
              "[850 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aee69ac2-d73b-4f62-beb5-0a58990b95b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Abs PM</th>\n",
              "      <th>Agg_Occ_min</th>\n",
              "      <th>Agg_Occ_max</th>\n",
              "      <th>Agg_Occ_mean</th>\n",
              "      <th>Agg_Occ_std</th>\n",
              "      <th>Agg_Speed_min</th>\n",
              "      <th>Agg_Speed_max</th>\n",
              "      <th>Agg_Speed_mean</th>\n",
              "      <th>Agg_Speed_std</th>\n",
              "      <th>Agg_Flow_min</th>\n",
              "      <th>Agg_Flow_max</th>\n",
              "      <th>Agg_Flow_mean</th>\n",
              "      <th>Agg_Flow_std</th>\n",
              "      <th>Agg_Delay_min</th>\n",
              "      <th>Agg_Delay_max</th>\n",
              "      <th>Agg_Delay_mean</th>\n",
              "      <th>Agg_Delay_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.461</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>0.1001</td>\n",
              "      <td>0.089563</td>\n",
              "      <td>0.006311</td>\n",
              "      <td>64.5</td>\n",
              "      <td>68.4</td>\n",
              "      <td>66.187500</td>\n",
              "      <td>1.692367</td>\n",
              "      <td>340.0</td>\n",
              "      <td>398.0</td>\n",
              "      <td>366.125000</td>\n",
              "      <td>18.795421</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.645</td>\n",
              "      <td>0.3258</td>\n",
              "      <td>0.3447</td>\n",
              "      <td>0.335989</td>\n",
              "      <td>0.007217</td>\n",
              "      <td>20.4</td>\n",
              "      <td>21.1</td>\n",
              "      <td>20.766667</td>\n",
              "      <td>0.269258</td>\n",
              "      <td>443.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>449.888889</td>\n",
              "      <td>6.845518</td>\n",
              "      <td>91.15</td>\n",
              "      <td>94.37</td>\n",
              "      <td>92.644444</td>\n",
              "      <td>0.957981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>32.500</td>\n",
              "      <td>0.1494</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.157388</td>\n",
              "      <td>0.004639</td>\n",
              "      <td>35.6</td>\n",
              "      <td>40.1</td>\n",
              "      <td>38.662500</td>\n",
              "      <td>1.581082</td>\n",
              "      <td>444.0</td>\n",
              "      <td>469.0</td>\n",
              "      <td>458.875000</td>\n",
              "      <td>8.322731</td>\n",
              "      <td>19.96</td>\n",
              "      <td>26.78</td>\n",
              "      <td>22.346250</td>\n",
              "      <td>2.296282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.075</td>\n",
              "      <td>0.3094</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.320700</td>\n",
              "      <td>0.008605</td>\n",
              "      <td>20.2</td>\n",
              "      <td>22.9</td>\n",
              "      <td>21.630000</td>\n",
              "      <td>0.905600</td>\n",
              "      <td>453.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>468.700000</td>\n",
              "      <td>10.509784</td>\n",
              "      <td>81.82</td>\n",
              "      <td>93.72</td>\n",
              "      <td>87.404000</td>\n",
              "      <td>3.813348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.876</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0715</td>\n",
              "      <td>0.069890</td>\n",
              "      <td>0.001016</td>\n",
              "      <td>62.9</td>\n",
              "      <td>63.5</td>\n",
              "      <td>63.230000</td>\n",
              "      <td>0.188856</td>\n",
              "      <td>260.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>270.100000</td>\n",
              "      <td>5.173651</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>86.670</td>\n",
              "      <td>0.0391</td>\n",
              "      <td>0.0430</td>\n",
              "      <td>0.040725</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>62.8</td>\n",
              "      <td>63.1</td>\n",
              "      <td>62.937500</td>\n",
              "      <td>0.106066</td>\n",
              "      <td>139.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>146.125000</td>\n",
              "      <td>5.194434</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>8.145</td>\n",
              "      <td>0.0862</td>\n",
              "      <td>0.0987</td>\n",
              "      <td>0.092033</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>66.6</td>\n",
              "      <td>67.5</td>\n",
              "      <td>67.155556</td>\n",
              "      <td>0.332081</td>\n",
              "      <td>455.0</td>\n",
              "      <td>505.0</td>\n",
              "      <td>479.333333</td>\n",
              "      <td>17.109939</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>8.145</td>\n",
              "      <td>0.0826</td>\n",
              "      <td>0.0923</td>\n",
              "      <td>0.086100</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>66.8</td>\n",
              "      <td>67.8</td>\n",
              "      <td>67.162500</td>\n",
              "      <td>0.318067</td>\n",
              "      <td>433.0</td>\n",
              "      <td>481.0</td>\n",
              "      <td>453.437500</td>\n",
              "      <td>12.951030</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>10.075</td>\n",
              "      <td>0.0823</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>0.084022</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>67.5</td>\n",
              "      <td>68.9</td>\n",
              "      <td>67.811111</td>\n",
              "      <td>0.518277</td>\n",
              "      <td>432.0</td>\n",
              "      <td>451.0</td>\n",
              "      <td>442.666667</td>\n",
              "      <td>7.245688</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>194.303</td>\n",
              "      <td>0.0149</td>\n",
              "      <td>0.0209</td>\n",
              "      <td>0.017927</td>\n",
              "      <td>0.002104</td>\n",
              "      <td>65.1</td>\n",
              "      <td>65.2</td>\n",
              "      <td>65.181818</td>\n",
              "      <td>0.040452</td>\n",
              "      <td>25.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>31.181818</td>\n",
              "      <td>4.045199</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>850 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aee69ac2-d73b-4f62-beb5-0a58990b95b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aee69ac2-d73b-4f62-beb5-0a58990b95b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aee69ac2-d73b-4f62-beb5-0a58990b95b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X[\"Abs PM\"].unique())"
      ],
      "metadata": {
        "id": "U9uqSRrTmD_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X1, Y, test_size = 0.2, random_state = 20)"
      ],
      "metadata": {
        "id": "EB2JGm2UpyFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY35XMmlxF5k",
        "outputId": "7e4b05c5-7469-4bee-895c-177dd272f73d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "6khzuHypxKa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCP0WHJaxON5",
        "outputId": "e4d0619e-6775-4041-c0ca-45f5cee4ddb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 20.097588870236542\n",
            "Mean Squared Error: 1163.5948816914445\n",
            "Root Mean Squared Error: 34.11150658782817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear, elastic net, svr, ann, knn"
      ],
      "metadata": {
        "id": "dC-Nh_uF6pGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def cross_val(model):\n",
        "    pred = cross_val_score(model, X, y, cv=10)\n",
        "    return pred.mean()\n",
        "\n",
        "def print_evaluate(true, predicted):  \n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    print('MAE:', mae)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R2 Square', r2_square)\n",
        "    print('__________________________________')\n",
        "    \n",
        "def evaluate(true, predicted):\n",
        "    mae = metrics.mean_absolute_error(true, predicted)\n",
        "    mse = metrics.mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
        "    r2_square = metrics.r2_score(true, predicted)\n",
        "    return mae, mse, rmse, r2_square"
      ],
      "metadata": {
        "id": "RKVvaso63LR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = regressor.predict(X_test)\n",
        "train_pred = regressor.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n",
        "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0eB3QF429BG",
        "outputId": "0eae2a7e-d019-4873-8b45-d162f1973a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 20.097588870236542\n",
            "MSE: 1163.5948816914445\n",
            "RMSE: 34.11150658782817\n",
            "R2 Square 0.7994132557587036\n",
            "__________________________________\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 20.6573094963516\n",
            "MSE: 1240.944825941336\n",
            "RMSE: 35.22704679562759\n",
            "R2 Square 0.7162195898631387\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "model = RANSACRegressor(base_estimator=LinearRegression(), max_trials=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Robust Regression\", *evaluate(y_test, test_pred) , cross_val(RANSACRegressor())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVIHGZlG3gLp",
        "outputId": "79e92656-45d0-4f0e-f079-a4981b547530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 75.71331976297446\n",
            "MSE: 49413.07955077678\n",
            "RMSE: 222.29052960208804\n",
            "R2 Square -7.518092427167277\n",
            "__________________________________\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 73.40358698458061\n",
            "MSE: 41359.3961991558\n",
            "RMSE: 203.37009661982216\n",
            "R2 Square -8.458104962487855\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "model = Ridge(alpha=100, solver='cholesky', tol=0.0001, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Ridge Regression\", *evaluate(y_test, test_pred) , cross_val(Ridge())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2NWwPVx3rIw",
        "outputId": "37e0f9e6-6795-4402-a8f3-5e67db65be21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 18.891473005472285\n",
            "MSE: 888.8668611018308\n",
            "RMSE: 29.81387028048909\n",
            "R2 Square 0.8467723496057143\n",
            "__________________________________\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 22.372199640986352\n",
            "MSE: 1638.4519037071402\n",
            "RMSE: 40.477795193255524\n",
            "R2 Square 0.6253173037964591\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "model = Lasso(alpha=0.1, \n",
        "              precompute=True, \n",
        "#               warm_start=True, \n",
        "              positive=True, \n",
        "              selection='random',\n",
        "              random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Lasso Regression\", *evaluate(y_test, test_pred) , cross_val(Lasso())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZHV7sB43wgJ",
        "outputId": "579ae8d2-4214-4caa-9032-f3750ea49bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 27.92090814657124\n",
            "MSE: 3633.54563849952\n",
            "RMSE: 60.27889878306935\n",
            "R2 Square 0.37362985937226634\n",
            "__________________________________\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 28.5198471027544\n",
            "MSE: 3135.4947964223334\n",
            "RMSE: 55.99548907208806\n",
            "R2 Square 0.2829721509691132\n",
            "__________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.222e-01, tolerance: 6.575e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.154e+00, tolerance: 8.066e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.275e-01, tolerance: 5.982e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "model = ElasticNet(alpha=0.1, l1_ratio=0.9, selection='random', random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Elastic Net Regression\", *evaluate(y_test, test_pred) , cross_val(ElasticNet())]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQGF6wMt30r1",
        "outputId": "8a19bc8c-0138-4b2f-cf1b-0d0e9b3c692c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.684e+05, tolerance: 2.974e+02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.240e+01, tolerance: 8.051e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+01, tolerance: 8.241e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+00, tolerance: 6.575e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 19.79449402588143\n",
            "MSE: 1192.1256908435398\n",
            "RMSE: 34.527173224049776\n",
            "R2 Square 0.7944949614206694\n",
            "__________________________________\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 22.1768771300346\n",
            "MSE: 1609.4249639152247\n",
            "RMSE: 40.11763906207872\n",
            "R2 Square 0.6319552112255177\n",
            "__________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+01, tolerance: 8.330e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.633e+01, tolerance: 7.715e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+01, tolerance: 8.066e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+01, tolerance: 7.849e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+01, tolerance: 5.982e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.516e+01, tolerance: 8.228e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.257e+00, tolerance: 7.459e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "sgd_reg = SGDRegressor(n_iter_no_change=250, penalty=None, eta0=0.0001, max_iter=100000)\n",
        "sgd_reg.fit(X_train, y_train)\n",
        "\n",
        "test_pred = sgd_reg.predict(X_test)\n",
        "train_pred = sgd_reg.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "print('====================================')\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred), 0]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-rMTd6w34yL",
        "outputId": "1eb8a9ff-25f5-4587-a943-4d13b42da5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 47771145.60332336\n",
            "MSE: 7659502834251279.0\n",
            "RMSE: 87518585.65042786\n",
            "R2 Square -1320386296126.4685\n",
            "__________________________________\n",
            "====================================\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 51255784.7038454\n",
            "MSE: 8936569966266639.0\n",
            "RMSE: 94533433.06083113\n",
            "R2 Square -2043623082371.069\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer=Adam(0.00001), loss='mse')\n",
        "\n",
        "r = model.fit(X_train, y_train,\n",
        "              validation_data=(X_test,y_test),\n",
        "              batch_size=100,\n",
        "              epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItPNbg_k3-aN",
        "outputId": "c24815a6-e105-4245-f30f-f2b6627376f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 2s 69ms/step - loss: 5499.9980 - val_loss: 6788.9204\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 5438.7329 - val_loss: 6703.2471\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 5266.3403 - val_loss: 6622.3789\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 5220.4302 - val_loss: 6547.8789\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 5119.0820 - val_loss: 6480.2954\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 5083.7461 - val_loss: 6419.6743\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 5003.6416 - val_loss: 6362.5366\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4904.0205 - val_loss: 6309.6885\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 4824.5811 - val_loss: 6263.3794\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4801.4492 - val_loss: 6223.8955\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 4786.0435 - val_loss: 6187.8921\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 4720.4771 - val_loss: 6154.0884\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4686.8086 - val_loss: 6125.2881\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 4667.4307 - val_loss: 6100.5962\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 4635.2241 - val_loss: 6076.6948\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 4629.6318 - val_loss: 6056.3921\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 4630.7080 - val_loss: 6036.8564\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 4569.2891 - val_loss: 6021.3179\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 4570.2222 - val_loss: 6005.7905\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 4560.1040 - val_loss: 5992.7969\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 4550.9023 - val_loss: 5982.5049\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 4501.1040 - val_loss: 5972.9116\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4573.4443 - val_loss: 5963.0273\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4488.2642 - val_loss: 5954.6631\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4528.9131 - val_loss: 5946.8735\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4486.3867 - val_loss: 5941.1064\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4541.7124 - val_loss: 5935.1055\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4507.3022 - val_loss: 5928.9424\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4559.2456 - val_loss: 5922.6963\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4448.2793 - val_loss: 5917.8662\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4544.2114 - val_loss: 5912.6572\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4492.5435 - val_loss: 5908.0859\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4501.8477 - val_loss: 5903.3950\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4487.9102 - val_loss: 5899.4844\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4503.7471 - val_loss: 5895.4351\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4486.6396 - val_loss: 5891.7329\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4499.7065 - val_loss: 5887.5068\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 4429.2197 - val_loss: 5882.8428\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4424.4761 - val_loss: 5878.9712\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4442.6045 - val_loss: 5874.8887\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4432.3726 - val_loss: 5870.9619\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4446.3564 - val_loss: 5866.7168\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4500.9712 - val_loss: 5862.4048\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4401.9912 - val_loss: 5858.2944\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4434.0171 - val_loss: 5854.9448\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4471.9087 - val_loss: 5850.9697\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4441.8770 - val_loss: 5846.5386\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4430.2959 - val_loss: 5842.2310\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4417.5049 - val_loss: 5838.5996\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4449.4595 - val_loss: 5834.8579\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4473.2227 - val_loss: 5831.7720\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4467.1699 - val_loss: 5827.7104\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4470.8799 - val_loss: 5824.1572\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4417.0830 - val_loss: 5820.6938\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4435.5151 - val_loss: 5816.9126\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4432.1377 - val_loss: 5813.5967\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4390.6216 - val_loss: 5809.1074\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4462.9355 - val_loss: 5804.9009\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4429.8491 - val_loss: 5800.8271\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4395.5889 - val_loss: 5796.5903\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4422.3936 - val_loss: 5793.0386\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4407.3384 - val_loss: 5789.7168\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4342.7480 - val_loss: 5785.5771\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4353.1763 - val_loss: 5782.2744\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4391.6133 - val_loss: 5777.2456\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4396.8501 - val_loss: 5773.3809\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4406.5200 - val_loss: 5770.2397\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4416.0723 - val_loss: 5767.7275\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4394.0229 - val_loss: 5763.9116\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4431.1499 - val_loss: 5759.1802\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4349.2334 - val_loss: 5756.6416\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4359.2432 - val_loss: 5752.2622\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4359.4487 - val_loss: 5747.7197\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4363.3086 - val_loss: 5743.0679\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4316.8057 - val_loss: 5739.4023\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4327.3086 - val_loss: 5735.2871\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4409.8730 - val_loss: 5730.6538\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 4339.7656 - val_loss: 5726.8101\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4309.1689 - val_loss: 5722.3545\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4375.3447 - val_loss: 5717.8086\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4341.6465 - val_loss: 5715.5669\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4416.6279 - val_loss: 5711.2983\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4416.4961 - val_loss: 5707.8320\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4295.0293 - val_loss: 5704.3486\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4366.6660 - val_loss: 5700.9995\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4281.7710 - val_loss: 5696.5073\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4287.0308 - val_loss: 5691.6470\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4385.2085 - val_loss: 5687.7715\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4409.9692 - val_loss: 5684.6021\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4367.5225 - val_loss: 5681.9424\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4259.2002 - val_loss: 5678.6992\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4374.1172 - val_loss: 5673.3521\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 4365.4629 - val_loss: 5669.8853\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4295.5820 - val_loss: 5666.5630\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4270.4771 - val_loss: 5662.6875\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4367.4756 - val_loss: 5658.9277\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4295.7773 - val_loss: 5655.6157\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4331.9810 - val_loss: 5650.8848\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4254.1719 - val_loss: 5646.4736\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4272.8149 - val_loss: 5641.7554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u08Zmp16CG79",
        "outputId": "1612899a-42bd-4077-aaf8-30fdd905775a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_51 (Dense)            (None, 17)                306       \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 32)                576       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 512)               66048     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,875\n",
            "Trainable params: 77,875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred = model.predict(X_test)\n",
        "train_pred = model.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Artficial Neural Network\", *evaluate(y_test, test_pred), 0]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWLgpDpP4HuW",
        "outputId": "452e2e59-173b-462c-b08b-f626f95c0489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 24.77105462691363\n",
            "MSE: 5641.755285295931\n",
            "RMSE: 75.11161884353133\n",
            "R2 Square 0.027443879059856013\n",
            "__________________________________\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 26.45813185888178\n",
            "MSE: 4297.161197975579\n",
            "RMSE: 65.55273600678754\n",
            "R2 Square 0.017321204219788444\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "test_pred = rf_reg.predict(X_test)\n",
        "train_pred = rf_reg.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Random Forest Regressor\", *evaluate(y_test, test_pred), 0]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWfGTBv74XgK",
        "outputId": "30e13b6e-f4ab-4aa1-dac0-9309b71c6a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 24.05990109243697\n",
            "MSE: 3989.55256869914\n",
            "RMSE: 63.1629050052255\n",
            "R2 Square 0.31225946991827036\n",
            "__________________________________\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 9.688783325163397\n",
            "MSE: 455.2120415330498\n",
            "RMSE: 21.335698758959122\n",
            "R2 Square 0.8959016894667373\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm_reg = SVR(kernel='rbf', C=1000000, epsilon=0.001)\n",
        "svm_reg.fit(X_train, y_train)\n",
        "\n",
        "test_pred = svm_reg.predict(X_test)\n",
        "train_pred = svm_reg.predict(X_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"SVM Regressor\", *evaluate(y_test, test_pred), 0]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EavyvSXv4cX_",
        "outputId": "36872d94-d7e5-44f0-a87f-9e5c6354d5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 15.877884721370286\n",
            "MSE: 902.6360855825543\n",
            "RMSE: 30.04390263568557\n",
            "R2 Square 0.8443987366302936\n",
            "__________________________________\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 13.458296680905514\n",
            "MSE: 1093.3967284683638\n",
            "RMSE: 33.066549993435416\n",
            "R2 Square 0.7499610252118308\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_Y = np.mean(df1['Duration (mins)'])\n",
        "mean_Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WRZ7AErxYNZ",
        "outputId": "6171a72e-6bbf-4c7a-d7dd-e66a2f0e9e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.528235294117646"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import r2_score, mean_squared_error"
      ],
      "metadata": {
        "id": "xQIODg_I0xkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN\n",
        "knn_model = KNeighborsRegressor()\n",
        "param_grid = {'n_neighbors':np.arange(5, 200, 5)}\n",
        "gsModelTrain = GridSearchCV(estimator = knn_model, param_grid = param_grid, cv=2)\n",
        "gsModelTrain.fit(X_train, y_train)\n",
        "knn_model.set_params(**gsModelTrain.best_params_)\n",
        "#fit to train data\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "print('Test set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_test, test_pred)\n",
        "\n",
        "print('Train set evaluation:\\n_____________________________________')\n",
        "print_evaluate(y_train, train_pred)\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"KNeighborsRegressor\", *evaluate(y_test, test_pred), 0]], \n",
        "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7JcWr1bxz6s",
        "outputId": "f5cf8c4f-7c49-4c43-c5e5-bf3969682137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set evaluation:\n",
            "_____________________________________\n",
            "MAE: 15.877884721370286\n",
            "MSE: 902.6360855825543\n",
            "RMSE: 30.04390263568557\n",
            "R2 Square 0.8443987366302936\n",
            "__________________________________\n",
            "Train set evaluation:\n",
            "_____________________________________\n",
            "MAE: 13.458296680905514\n",
            "MSE: 1093.3967284683638\n",
            "RMSE: 33.066549993435416\n",
            "R2 Square 0.7499610252118308\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale data, otherwise model will fail.\n",
        "#Standardize features by removing the mean and scaling to unit variance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "5PynO12wp4Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "#Experiment with deeper and wider networks\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=17, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#Output layer\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs =100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6mqVGjp7rs",
        "outputId": "1d597f10-eeee-409a-cac1-211dc5658eb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 128)               2304      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,625\n",
            "Trainable params: 10,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "17/17 [==============================] - 1s 11ms/step - loss: 5987.5825 - val_loss: 2385.4807\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5813.7915 - val_loss: 2294.0701\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 5569.8364 - val_loss: 2174.3625\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 5283.9072 - val_loss: 2076.3828\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4918.3115 - val_loss: 2063.2063\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 4637.6992 - val_loss: 2066.1626\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4386.0068 - val_loss: 2062.1272\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 4225.2305 - val_loss: 2061.2380\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 4000.9932 - val_loss: 2068.0476\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3842.4519 - val_loss: 2044.5338\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3717.9512 - val_loss: 2074.1824\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3609.3613 - val_loss: 2112.0085\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3517.5435 - val_loss: 2154.2190\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3442.5857 - val_loss: 2190.0918\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3368.7703 - val_loss: 2241.6567\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 3299.8535 - val_loss: 2262.6057\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3272.5483 - val_loss: 2231.6011\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3208.3188 - val_loss: 2302.3982\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3156.6377 - val_loss: 2297.5938\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3131.8701 - val_loss: 2343.1167\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 3099.6580 - val_loss: 2402.3923\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3056.2988 - val_loss: 2385.6555\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3047.2043 - val_loss: 2387.0930\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2999.4858 - val_loss: 2369.4146\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 3006.1973 - val_loss: 2406.2480\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2959.4854 - val_loss: 2456.8757\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2949.4944 - val_loss: 2391.3474\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2879.5049 - val_loss: 2395.6045\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2906.3635 - val_loss: 2347.1462\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2891.2642 - val_loss: 2448.6228\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2831.9177 - val_loss: 2433.6885\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2783.3813 - val_loss: 2395.8186\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2791.1396 - val_loss: 2388.6992\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2765.2593 - val_loss: 2400.5762\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2736.0339 - val_loss: 2358.8350\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2713.0708 - val_loss: 2426.4783\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2676.1392 - val_loss: 2339.8530\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2628.3030 - val_loss: 2340.1284\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2606.3767 - val_loss: 2388.2607\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2580.4709 - val_loss: 2345.9343\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2541.8098 - val_loss: 2332.0693\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2541.2344 - val_loss: 2418.4148\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2509.3254 - val_loss: 2338.9885\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2464.6836 - val_loss: 2308.4351\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2430.2065 - val_loss: 2356.5000\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2423.6199 - val_loss: 2283.5962\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2385.7881 - val_loss: 2317.8228\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 2362.8796 - val_loss: 2293.5859\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2323.9160 - val_loss: 2291.2134\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2317.0508 - val_loss: 2234.1528\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2306.0063 - val_loss: 2173.5427\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2251.5137 - val_loss: 2274.2639\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2230.7646 - val_loss: 2288.5278\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2212.7046 - val_loss: 2215.9626\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2180.6853 - val_loss: 2218.4358\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2167.3503 - val_loss: 2245.1582\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2127.6809 - val_loss: 2208.6536\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2117.3879 - val_loss: 2094.3752\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2104.3535 - val_loss: 2239.5449\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2059.3875 - val_loss: 2189.5444\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 2039.8469 - val_loss: 2166.8079\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 2004.1080 - val_loss: 2152.9705\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1996.7560 - val_loss: 2155.5256\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1957.9393 - val_loss: 2141.5332\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1945.4281 - val_loss: 2163.9980\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1950.5305 - val_loss: 2063.7407\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1892.1735 - val_loss: 2115.6453\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1884.2365 - val_loss: 2161.9724\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1863.0636 - val_loss: 2108.6250\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1844.2900 - val_loss: 1991.3844\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1834.8384 - val_loss: 2056.8325\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1794.1372 - val_loss: 2109.4204\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1781.1362 - val_loss: 1998.8120\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1771.5905 - val_loss: 2117.6631\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1751.1385 - val_loss: 1972.8091\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1716.4784 - val_loss: 2084.9861\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1688.5836 - val_loss: 1984.7500\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1681.5736 - val_loss: 2062.0454\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1656.4160 - val_loss: 2017.3635\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1668.9153 - val_loss: 1995.8552\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1629.4692 - val_loss: 1945.8208\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1608.1772 - val_loss: 2028.2217\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1588.2272 - val_loss: 1952.2098\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1566.1108 - val_loss: 1962.6459\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1573.7682 - val_loss: 2010.2078\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1538.1024 - val_loss: 1888.2469\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1523.7250 - val_loss: 1980.5756\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1511.3352 - val_loss: 1971.1023\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1496.5219 - val_loss: 1924.3376\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1472.3591 - val_loss: 1940.5852\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1484.7876 - val_loss: 1943.1218\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1454.0242 - val_loss: 1910.3152\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1430.6968 - val_loss: 1917.7400\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1427.6865 - val_loss: 1925.5051\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1414.5143 - val_loss: 1821.5253\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1393.1119 - val_loss: 1919.8154\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 1372.1620 - val_loss: 1896.9564\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1391.1593 - val_loss: 1916.8381\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 1363.6797 - val_loss: 1888.2351\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 1362.4987 - val_loss: 1831.9276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "o8mT2IUYqXui",
        "outputId": "1e626e28-f0c6-4c8b-f30d-7ab2e55e4640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zV1f348dc7O2RPVpjKEGSHobhw48I9aqs4q7XOulurX6udtrX8rNu6akVqK1IVF4KgONgbBNkrgew9378/zicQMIvk3lySvJ+PRx6593zW+3Nvct/3nPM55yOqijHGGNOQoEAHYIwx5vBnycIYY0yjLFkYY4xplCULY4wxjbJkYYwxplGWLIwxxjTKkoVpdSIyU0Su9vW6gSQim0XkVD/sV0XkSO/xsyLyUFPWbcZxrhSRj5sbZwP7PUlEtvt6v6b1hQQ6ANM2iEhhraedgDKgynv+U1V9o6n7UtWJ/li3vVPVm3yxHxHpDWwCQlW10tv3G0CT30PT8ViyME2iqtE1j0VkM3C9qn568HoiElLzAWSMaT+sGcq0SE0zg4jcJyK7gZdFJEFE3hORPSKS4z1Oq7XNHBG53ns8WUS+EJEnvHU3icjEZq7bR0TmikiBiHwqIn8XkX/WE3dTYvyNiHzp7e9jEUmutfwnIrJFRLJE5JcNvD5jRWS3iATXKrtARJZ7j8eIyFcikisiu0TkKREJq2dfr4jIY7We3+Nts1NErj1o3bNFZImI5IvINhF5pNbiud7vXBEpFJFjal7bWtsfKyILRCTP+31sU1+bhojIUd72uSKySkTOq7XsLBFZ7e1zh4jc7ZUne+9Prohki8g8EbHPrlZmL7jxhS5AItALuBH3d/Wy97wnUAI81cD2Y4F1QDLwR+AlEZFmrPsv4FsgCXgE+EkDx2xKjD8CrgFSgTCg5sNrEPCMt/9u3vHSqIOqfgMUAScftN9/eY+rgDu98zkGOAX4WQNx48VwphfPaUA/4OD+kiLgKiAeOBu4WUTO95ad4P2OV9VoVf3qoH0nAu8DU7xz+wvwvogkHXQOP3htGok5FPgf8LG33a3AGyIywFvlJVyTZgxwNPCZV/4LYDuQAnQGHgRsnqJWZsnC+EI18LCqlqlqiapmqep/VLVYVQuAx4ETG9h+i6q+oKpVwKtAV9yHQpPXFZGewGjg16parqpfADPqO2ATY3xZVb9T1RJgGjDcK78YeE9V56pqGfCQ9xrU503gCgARiQHO8spQ1UWq+rWqVqrqZuC5OuKoy6VefCtVtQiXHGuf3xxVXaGq1aq63DteU/YLLrmsV9XXvbjeBNYC59Zap77XpiHjgGjg99579BnwHt5rA1QAg0QkVlVzVHVxrfKuQC9VrVDVeWqT2rU6SxbGF/aoamnNExHpJCLPec00+bhmj/jaTTEH2V3zQFWLvYfRh7huNyC7VhnAtvoCbmKMu2s9Lq4VU7fa+/Y+rLPqOxauFnGhiIQDFwKLVXWLF0d/r4lltxfHb3G1jMYcEAOw5aDzGysis71mtjzgpibut2bfWw4q2wJ0r/W8vtem0ZhVtXZirb3fi3CJdIuIfC4ix3jlfwI2AB+LyEYRub9pp2F8yZKF8YWDv+X9AhgAjFXVWPY3e9TXtOQLu4BEEelUq6xHA+u3JMZdtfftHTOpvpVVdTXuQ3EiBzZBgWvOWgv08+J4sDkx4JrSavsXrmbVQ1XjgGdr7bexb+U7cc1ztfUEdjQhrsb22+Og/oZ9+1XVBao6CddENR1XY0FVC1T1F6raFzgPuEtETmlhLOYQWbIw/hCD6wPI9dq/H/b3Ab1v6guBR0QkzPtWem4Dm7QkxreBc0TkOK8z+lEa/1/6F3A7Lin9+6A48oFCERkI3NzEGKYBk0VkkJesDo4/BlfTKhWRMbgkVWMPrtmsbz37/gDoLyI/EpEQEbkMGIRrMmqJb3C1kHtFJFRETsK9R1O99+xKEYlT1Qrca1INICLniMiRXt9UHq6fp6FmP+MHliyMPzwJRAJ7ga+BD1vpuFfiOomzgMeAt3DjQerS7BhVdRVwCy4B7AJycB2wDanpM/hMVffWKr8b90FeALzgxdyUGGZ65/AZronms4NW+RnwqIgUAL/G+5bubVuM66P50rvCaNxB+84CzsHVvrKAe4FzDor7kKlqOS45TMS97k8DV6nqWm+VnwCbvea4m3DvJ7gO/E+BQuAr4GlVnd2SWMyhE+snMu2ViLwFrFVVv9dsjGnvrGZh2g0RGS0iR4hIkHdp6SRc27cxpoVsBLdpT7oA/8V1Nm8HblbVJYENyZj2wZqhjDHGNMqaoYwxxjSqXTZDJScna+/evQMdhjHGtCmLFi3aq6opdS1rl8mid+/eLFy4MNBhGGNMmyIiB4/c38eaoYwxxjTKkoUxxphG+TVZiEi8iLwtImtFZI03b36iiHwiIuu93wneuiIiU0Rkg4gsF5GRtfZztbf+emkDt9g0xpj2xt99Fn8DPlTVi705dDrhJkqbpaq/92aPvB+4DzcFQD/vZyxugrWxtebtScdNgLZIRGaoao6fYzfGHIKKigq2b99OaWlp4yubgIqIiCAtLY3Q0NAmb+O3ZCEicbhJ0ybDvnlhykVkEnCSt9qrwBxcspgEvObNU/+1Vyvp6q37iapme/v9BDgT734AxpjDw/bt24mJiaF3797Uf+8qE2iqSlZWFtu3b6dPnz5N3s6fzVB9cLNbvizu9o4vikgU0FlVd3nr7Gb/TW66c+D8/Nu9svrKjTGHkdLSUpKSkixRHOZEhKSkpEOuAfozWYQAI4FnVHUE7jaPB9y0xKtF+GQIuYjcKCILRWThnj17fLFLY8whskTRNjTnffJnstgObPfuQQzuHgAjgQyveQnvd6a3fAcH3swlzSurr/wAqvq8qqaranpKSp1jShpVWrqdDRvuprzcko0xxtTmt2ShqruBbbVuxn4KsBp3966aK5quBt71Hs8ArvKuihoH5HnNVR8Bp4tIgnfl1Olemc9VVeWzffufych43R+7N8b4UVZWFsOHD2f48OF06dKF7t2773teXl7e4LYLFy7ktttua/QYxx57rE9inTNnDuecc45P9tVa/H011K3AG96VUBuBa3AJapqIXIe71eSl3rof4O6/uwF3N61rAFQ1W0R+Ayzw1nu0prPb16KiBhEbO45du14iLe1Oq1Ib04YkJSWxdOlSAB555BGio6O5++679y2vrKwkJKTuj7z09HTS09MbPcb8+fN9E2wb5NdxFqq61GsaGqqq56tqjqpmqeopqtpPVU+t+eBX5xZVPUJVh6jqwlr7+YeqHun9vOzPmLt2vZ7i4tXk53/tz8MYY1rB5MmTuemmmxg7diz33nsv3377LccccwwjRozg2GOPZd26dcCB3/QfeeQRrr32Wk466ST69u3LlClT9u0vOjp63/onnXQSF198MQMHDuTKK6+kZgbvDz74gIEDBzJq1Chuu+22RmsQ2dnZnH/++QwdOpRx48axfPlyAD7//PN9NaMRI0ZQUFDArl27OOGEExg+fDhHH3008+bN8/lrVp92OTdUS6SkXMr69beza9dLxMUdE+hwjGmT1q+/g8LCpT7dZ3T0cPr1e/KQt9u+fTvz588nODiY/Px85s2bR0hICJ9++ikPPvgg//nPf36wzdq1a5k9ezYFBQUMGDCAm2+++QdjEpYsWcKqVavo1q0b48eP58svvyQ9PZ2f/vSnzJ07lz59+nDFFVc0Gt/DDz/MiBEjmD59Op999hlXXXUVS5cu5YknnuDvf/8748ePp7CwkIiICJ5//nnOOOMMfvnLX1JVVUVxcfEhvx7NZdN9HCQkJIbU1MvJzJxKZWVBoMMxxrTQJZdcQnBwMAB5eXlccsklHH300dx5552sWrWqzm3OPvtswsPDSU5OJjU1lYyMjB+sM2bMGNLS0ggKCmL48OFs3ryZtWvX0rdv333jF5qSLL744gt+8pOfAHDyySeTlZVFfn4+48eP56677mLKlCnk5uYSEhLC6NGjefnll3nkkUdYsWIFMTExzX1ZDpnVLOrQtet17N79EpmZb9Gt2/WBDseYNqc5NQB/iYqK2vf4oYceYsKECbzzzjts3ryZk046qc5twsPD9z0ODg6msrKyWeu0xP3338/ZZ5/NBx98wPjx4/noo4844YQTmDt3Lu+//z6TJ0/mrrvu4qqrrvLpcetjNYs6xMaOo1Ono9i9+6VAh2KM8aG8vDy6d3djel955RWf73/AgAFs3LiRzZs3A/DWW281us3xxx/PG2+8Abi+kOTkZGJjY/n+++8ZMmQI9913H6NHj2bt2rVs2bKFzp07c8MNN3D99dezePFin59DfSxZ1EFE6Nr1evLzv6awcGWgwzHG+Mi9997LAw88wIgRI3xeEwCIjIzk6aef5swzz2TUqFHExMQQFxfX4DaPPPIIixYtYujQodx///28+uqrADz55JMcffTRDB06lNDQUCZOnMicOXMYNmwYI0aM4K233uL222/3+TnUp13egzs9PV1bevOj8vIM5s/vQu/ej9K790M+isyY9mvNmjUcddRRgQ4j4AoLC4mOjkZVueWWW+jXrx933nlnoMP6gbreLxFZpKp1XkNsNYt6hIV1Jjp6BDk5nwY6FGNMG/LCCy8wfPhwBg8eTF5eHj/96U8DHZJPWAd3AxISTmP79r9SWVlISEh0oMMxxrQBd95552FZk2gpq1k0ICHhVFQryMubG+hQjDEmoCxZNCAu7jhEwq0pyhjT4VmyaEBwcCRxcceRk/NJoEMxxpiAsmTRiMTE0ygqWklZ2e5Ah2KMMQFjyaIRCQmnAlhTlDGHuQkTJvDRRwfeveDJJ5/k5ptvrnebk046iZrL7M866yxyc3N/sM4jjzzCE0880eCxp0+fzurVq/c9//Wvf82nn7b8M+NwmsrckkUjoqNHEBKSaMnCmMPcFVdcwdSpUw8omzp1apPmZwI3W2x8fHyzjn1wsnj00Uc59dRTm7Wvw5Uli0aIBJGQcAo5OZ/QHgcwGtNeXHzxxbz//vv7bnS0efNmdu7cyfHHH8/NN99Meno6gwcP5uGHH65z+969e7N3714AHn/8cfr3789xxx23bxpzcGMoRo8ezbBhw7jooosoLi5m/vz5zJgxg3vuuYfhw4fz/fffM3nyZN5++20AZs2axYgRIxgyZAjXXnstZWVl+4738MMPM3LkSIYMGcLatWsbPL9AT2Vu4yyaICHhNPbs+TfFxWuJirIRqsY06o47YKlvpyhn+HB4sv4JChMTExkzZgwzZ85k0qRJTJ06lUsvvRQR4fHHHycxMZGqqipOOeUUli9fztChQ+vcz6JFi5g6dSpLly6lsrKSkSNHMmrUKAAuvPBCbrjhBgB+9atf8dJLL3Hrrbdy3nnncc4553DxxRcfsK/S0lImT57MrFmz6N+/P1dddRXPPPMMd9xxBwDJycksXryYp59+mieeeIIXX3yx3vML9FTmVrNoAuu3MKZtqN0UVbsJatq0aYwcOZIRI0awatWqA5qMDjZv3jwuuOACOnXqRGxsLOedd96+ZStXruT4449nyJAhvPHGG/VOcV5j3bp19OnTh/79+wNw9dVXM3fu/nFbF154IQCjRo3aN/lgfQI9lbnVLJogMrIPERG9yc2dTVrarYEOx5jDXwM1AH+aNGkSd955J4sXL6a4uJhRo0axadMmnnjiCRYsWEBCQgKTJ0+mtLS0WfufPHky06dPZ9iwYbzyyivMmTOnRfHWTHPekinOW2sqc6tZNFF8/ARycz9HtTrQoRhj6hEdHc2ECRO49tpr99Uq8vPziYqKIi4ujoyMDGbOnNngPk444QSmT59OSUkJBQUF/O9//9u3rKCggK5du1JRUbFvWnGAmJgYCgp+eLO0AQMGsHnzZjZs2ADA66+/zoknntiscwv0VOZWs2ii+PgJ7N79MoWFy4mJGR7ocIwx9bjiiiu44IIL9jVH1UzpPXDgQHr06MH48eMb3H7kyJFcdtllDBs2jNTUVEaPHr1v2W9+8xvGjh1LSkoKY8eO3ZcgLr/8cm644QamTJmyr2MbICIigpdffplLLrmEyspKRo8ezU033dSs86q5N/jQoUPp1KnTAVOZz549m6CgIAYPHszEiROZOnUqf/rTnwgNDSU6OprXXnutWceszaYob6LS0u18/XUPjjjiL/To0f4mCTOmpWyK8rbFpij3k4iINCIjjyQ3d3agQzHGmFZnyeIQuH6LuahWBToUY4xpVZYsDkF8/ASqqvIoKFgS6FCMOSy1x2bt9qg575Mli0MQH38SgDVFGVOHiIgIsrKyLGEc5lSVrKwsIiIiDmk7uxrqEISHd6VTp4Hk5s6mZ897Ah2OMYeVtLQ0tm/fzp49ewIdimlEREQEaWlph7SNJYtDFB8/gYyM16muriAoKDTQ4Rhz2AgNDaVPnz6BDsP4iTVDHSLXb1FIQcGiQIdijDGtxpLFIdrfbzEnoHEYY0xrsmRxiMLCUoiI6EthYcuHzxtjTFthyaIZoqOHU1jo4+mXjTHmMGbJohmio4dTUrKBysrCQIdijDGtwpJFM0RHDwOUoqIVgQ7FGGNahSWLZoiOdrPOWlOUMaajsGTRDOHhPQgJSbBkYYzpMPyaLERks4isEJGlIrLQK0sUkU9EZL33O8ErFxGZIiIbRGS5iIystZ+rvfXXi8jV/oy5KUSE6OhhFBYuC3QoxhjTKlqjZjFBVYfXmiP9fmCWqvYDZnnPASYC/byfG4FnwCUX4GFgLDAGeLgmwQRSdPRwioqW2wy0xpgOIRDNUJOAV73HrwLn1yp/TZ2vgXgR6QqcAXyiqtmqmgN8ApzZ2kEfLDp6ONXVJRQXrw90KMYY43f+ThYKfCwii0TkRq+ss6ru8h7vBjp7j7sD22ptu90rq6/8ACJyo4gsFJGFrTGRWU0nd1GRNUUZY9o/fyeL41R1JK6J6RYROaH2QnVzGftkPmNVfV5V01U1PSUlxRe7bFCnTkchEmqd3MaYDsGvyUJVd3i/M4F3cH0OGV7zEt7vTG/1HUCPWpuneWX1lQdUUFAYnToNsmRhjOkQ/JYsRCRKRGJqHgOnAyuBGUDNFU1XA+96j2cAV3lXRY0D8rzmqo+A00UkwevYPt0rCzib9sMY01H4834WnYF3RKTmOP9S1Q9FZAEwTUSuA7YAl3rrfwCcBWwAioFrAFQ1W0R+Ayzw1ntUVbP9GHeTRUcPIyPjVcrLMwgL69z4BsYY00b5LVmo6kZgWB3lWcApdZQrcEs9+/oH8A9fx9hS+0dyLyMx8fQAR2OMMf5jI7hbwM0RZdN+GGPaP0sWLRAamkhERB/y878OdCjGGONXlixaKD5+Arm5s20ktzGmXbNk0UIJCadSWZlLQcGSQIdijDF+Y8mihRISTgYgJ+fTAEdijDH+Y8mihcLCOhMVNcSShTGmXbNk4QMJCaeQl/cFVVUlgQ7FGGP8wpKFDyQknIpqGfn58wMdijHG+IUlCx+IizsBkRBycmYFOhRjjPELSxY+EBISQ0zMWOu3MMa0W5YsfCQh4VQKChZRUZET6FCMMcbnLFn4SELCKUA1ublzAh2KMcb4nCULH4mNHUtQUJQ1RRlj2iVLFj4SFBRGQsIEsrNn4ibQNcaY9sOShQ8lJp5NaekmiovXBjoUY4zxKUsWPpSUdDYAWVnvBTgSY4zxLUsWPhQR0YOoqKFkZb0f6FCMMcanLFn4WFLS2eTlfUFFRW6gQzHGGJ+xZOFjrimqipycjwMdijHG+IwlCx+LjR1HSEiiNUUZY9oVSxY+JhJMYuJEsrM/sLvnGWPaDUsWfpCUdDYVFXvJz18Q6FCMMcYnLFn4QWLiGUAQ2dnWFGWMaR8sWfhBaGgicXHHsWfPOzaa2xjTLliy8JPU1MspLl5FUdHyQIdijDEtZsnCT1JTL0UkhIyMfwY6FGOMaTFLFn4SGppEYuJEMjLetKuijDFtniULP+rc+ceUl+8gN/fzQIdijDEtYsnCj5KSziU4OMaaoowxbZ4lCz8KDo4kJeUi9uz5D1VVJYEOxxhjms2ShZ+lpl5JVVW+TVtujGnTLFn4WULCBMLCulpTlDGmTbNk4WciwaSm/ojs7A8oL98T6HCMMaZZLFm0gi5drka1kszMNwMdijHGNIsli1YQHT2E6OgR7N79aqBDMcaYZvF7shCRYBFZIiLvec/7iMg3IrJBRN4SkTCvPNx7vsFb3rvWPh7wyteJyBn+jtkfunS5msLCxRQWrgx0KMYYc8hao2ZxO7Cm1vM/AH9V1SOBHOA6r/w6IMcr/6u3HiIyCLgcGAycCTwtIsGtELdPpaZe4U3/YbULY0zb49dkISJpwNnAi95zAU4G3vZWeRU433s8yXuOt/wUb/1JwFRVLVPVTcAGYIw/4/aHsLBUb/qPf1JdXRnocIwx5pD4u2bxJHAvUO09TwJyVbXm03I70N173B3YBuAtz/PW31dexzb7iMiNIrJQRBbu2XN4XnXUpcvVlJfvJifn00CHYowxh8RvyUJEzgEyVXWRv45Rm6o+r6rpqpqekpLSGoc8ZElJ5xASksDu3a8EOhRjjDkk/qxZjAfOE5HNwFRc89PfgHgRCfHWSQN2eI93AD0AvOVxQFbt8jq2aVOCgsLp0uVq9ux5m4KCpYEOxxhjmsxvyUJVH1DVNFXtjeug/kxVrwRmAxd7q10NvOs9nuE9x1v+mbrbzM0ALveuluoD9AO+9Vfc/tar10OEhibx3Xc/tanLjTFtRiDGWdwH3CUiG3B9Ei955S8BSV75XcD9AKq6CpgGrAY+BG7RNvwpGxqayJFH/pWCgm/ZufPZQIdjjDFNIu3xHtHp6em6cOHCQIdRL1Vl+fLTyc//hjFj1hIe3i3QIRljDCKySFXT61rWpJqFiESJSJD3uL+InCciob4MsiMREfr1e4bq6nI2bLg90OEYY0yjmtoMNReIEJHuwMfAT4BX/BVUR9Cp05H06vUge/a8TX7+gkCHY4wxDWpqshBVLQYuBJ5W1UtwI6pNC6Sl3UFISAJbtjwW6FCMMaZBTU4WInIMcCXwvlfW5qbcONyEhMSSlnYHWVkzKCxcFuhwjDGmXk1NFncADwDvqOoqEemLuwTWtFD37rcRHBxrtQtjzGEtpPFVQFU/Bz4H8Dq696rqbf4MrKMIDY2ne/db2br1cYqKVhEVZa17xpjDT1OvhvqXiMSKSBSwElgtIvf4N7SOo0ePOwkKimLLlscDHYoxxtSpqc1Qg1Q1HzdD7EygD+6KKOMDoaFJdO/+czIzp5Kf/02gwzHGmB9oarII9cZVnA/MUNUKoP2N5gugXr0eJCysG+vWXU91dXmgwzHGmAM0NVk8B2wGooC5ItILyPdXUB1RSEgs/fs/Q1HRSrZu/UOgwzHGmAM0KVmo6hRV7a6qZ6mzBZjg59g6nOTkc0lJuYwtWx6jqGhN4xsYY0wraWoHd5yI/KXm5kIi8mdcLcP4WL9+UwgOjvaao+yOesaYw0NTm6H+ARQAl3o/+cDL/gqqIwsLS+XII/9Gfv581q+/hfY40aMxpu1p0jgL4AhVvajW8/8TEbt7j5906fJjiotXs3Xr7wgP70bv3g8HOiRjTAfX1GRRIiLHqeoXACIyHijxX1imT5/HKS/fxebNjxAW1pVu3W4MdEjGmA6sqcniJuA1EYnznuew/652xg9EhP79n6e8PJPvvruZ0NBUUlLOD3RYxpgOqqlXQy1T1WHAUGCoqo7A3VPb+FFQUCiDB08jJmY0a9ZcQW7uF4EOyRjTQR3SbVVVNd8byQ3u1qfGz4KDoxgy5D3Cw3uycuW5FBWtCnRIxpgOqCX34BafRWEaFBaWzNChHxEUFMmyZWfYdObGmFbXkmRh13S2osjI3gwd+iGqlSxaNJotWx63cRjGmFbTYLIQkQIRya/jpwDo1koxGk909FDGjFlFcvKFbNr0K5YsOZbi4u8CHZYxpgNoMFmoaoyqxtbxE6OqTb2SyvhQaGgSgwdPZdCgaZSUfM/ChSPYtesfNnjPGONXLWmGMgGUmnoJo0cvJzZ2HOvWXcfq1ZdRWZkX6LCMMe2UJYs2LDy8O8OGfULfvn9g7953WLLkBMrKdh2wjmqV1TqMMS1myaKNEwmiZ897GTLkA0pKvmfJkvEUF6+nvHwPGzc+wBdfJLBx4wOBDtMY08ZJe/zWmZ6ergsXLgx0GK0uP38BK1achWo11dWlVFeXEBHRh7KybYwZs47IyD6BDtEYcxgTkUWqml7XMqtZtCOxsaMZMeILIiJ6kZJyEaNHr2bEiLmIBLN5868DHZ4xpg2zK5ramU6dBpCevviAsrS0O9i69Q/06HE30dHDAhSZMaYts5pFB9Cjx32EhMRb34UxptksWXQAoaHx9Oz5INnZM8nMfIvq6opAh2SMaWMsWXQQ3bv/nIiIvqxefTlffpnI8uUT2bnzeaqqigMdmjGmDbBk0UEEB0cwatQiBg2aRufOV1FSsonvvvspX33Vk02bHqK8PCPQIRpjDmN26WwHpark5c1j27a/kJU1g+DgWI444gm6dr0OEZtQ2JiOyC6dNT8gIsTHn8CQIdMZPXo1MTEj+O67G1i27BQKC1faqG9jzAH8lixEJEJEvhWRZSKySkT+zyvvIyLfiMgGEXlLRMK88nDv+QZvee9a+3rAK18nImf4K+aOKipqIMOGzaJ//+coKFjIwoVD+Oqr7qxadSm7d7+OanWgQzTGBJg/axZlwMne7ViHA2eKyDjgD8BfVfVI3L28r/PWvw7I8cr/6q2HiAwCLgcGA2cCT4tIsB/j7pBEgujW7UbGjFlHv37PEB8/gfz8r1i79iqWLz+D0tJtgQ7RGBNAfksW6hR6T0O9H8Xdu/ttr/xV4Hzv8STvOd7yU8Q1nk8CpqpqmapuAjYAY/wVd0cXHt6V7t1vYtCgNxg3biv9+z9LXt5XLFhwtDcVelWgQzTGBIBf+yxEJFhElgKZwCfA90Cuqtbc4m070N173B3YBuAtzwOSapfXsU3tY90oIgtFZOGePXv8cTodjojQrdtPGT16OdHRw1i37joWLBhCRsZUay1/uecAAB/7SURBVJoypoPxa7JQ1SpVHQ6k4WoDA/14rOdVNV1V01NSUvx1mA4pMrIvw4fPYdCgtwBhzZorWLBgKHv2TLeOcGM6iFa5GkpVc4HZwDFAvIjUzEmVBuzwHu8AegB4y+OArNrldWxjWolIEKmplzJ69AoGDZqKaiWrVl3AkiXHkp39iQ3uM6ad8+fVUCkiEu89jgROA9bgksbF3mpXA+96j2d4z/GWf6bua+sM4HLvaqk+QD/gW3/FbRrmksZljB69kv79X6C0dBvLl5/OvHnRfP11H1asOJ+CgiWBDtMY42P+nHW2K/Cqd+VSEDBNVd8TkdXAVBF5DFgCvOSt/xLwuohsALJxV0ChqqtEZBqwGqgEblHrZQ24oKAQunW7ns6dryQ7eyZFRasoLl5NTs5nLF48hp49H6RXr18SFBQW6FCNMT5gI7iNT1VUZLNhw+1kZPyTqKih9Ox5H8nJ5xMc3CnQoRljGtHQCG67n4XxqdDQRI466nVSUi5hw4bbWbPmSoKDo0lOvoioqMGEhqYQFtaZ+PgTLYEY04ZYsjB+kZx8HklJ55CbO5eMjNfYs+c/ZGS8um95ZGQ/Bg58hbi4YwMYpTGmqawZyrQKVaWqqpCKij0UFa1g/frbKSvbSo8ev6B370cJDo4MdIjGdHg2kaAJOBEhJCSGyMi+JCdPYvToFXTtegPbtj3Bt98eRUbGmzZmw5jDmCULExAhITEMGPAcw4Z9RmhoAmvW/IjFi8exd++7VFeXBTo8Y8xBLFmYgEpImMCoUYsYOPAVysp2sHLl+Xz5ZSpr1lxNdvYnNq2IMYcJ6+A2AScSRJcuV5Oa+iNycz8jM/Mt9u59h4yM14iI6E2XLtfStet1hId3C3SoxnRY1sFtDkvV1WXs3TudnTtfIDd3FiKhpKb+iB497iY6+uhAh2dMu2TjLEybExQUTmrqZaSmXkZJyfds3/43du16iYyMV4mJGUt09DCioo4mPv4EoqOHBTpcY9o9q1mYNqOiIoudO58lO/tjiopWUFmZA0BKymX07fs7IiP7BDhCY9q2hmoWlixMm6SqlJfvYufO59i27U+oVtG16/UkJp5BXNxxhIYmBjpEY9ocSxamXSsr28GmTQ+RkfEGquUAxMSk06vXQyQlnYu74aIxpjE2KM+0a+Hh3Rk48B8cd1wew4fPpU+fx6iszGflykksWXI8ublfBDpEY9o8Sxam3QgOjiA+/nh69fqld7+N5ygt3cjSpcezZMmJ7N37no3bMKaZLFmYdikoKJRu3W5k7NgNHHHEXykt3cTKleeyYMFgvv/+fnJyZlFVVRroMI1pM6zPwnQI1dUVZGa+xa5dz5Of/xWqlQQFdaJr1xvo2fNeG/BnDNbBbcwBKisLyMubS2bmv8nI+CciIXTtej1du15LdPQI6xA3HZYlC3N4+fBDGDkSUlMDHQklJRvZuvX37N79MqqVhIf3Ijn5fJKTzyMu7niCgkIDHaIxrcauhjKtY9YsOOoo+PWvITu77nX+8x+YOBHS02HZssb3WVQEF18MEybAzJnQlC83a9fC449DZWWjq0ZG9mXAgOc55pidDBjwEtHRQ9m581mWLTuFL79MYfXqK9i27S/s3TuDoqLV2O3fTUdlNYuOKjsbMjKgf38IDq57nYIC+PZbSEmBbt0gKQnqa6JZtgyOPx7Cw2HvXoiOhltugV/9yj0G2LMHBg+Gzp0hJwfy8uDNN+Gcc+reZ06OW/b119ClC+zc6Wokf/gDnHpq3dtUVcHo0bBkCdxzD/zxj4f2ugCVlYXk5HxKVtYMsrI+oKIiY9+yTp0G0rv3o6SkXISIfdcy7UtDNQtUtd39jBo1SpstK6v527YVS5eqJiaqgmpUlOpxx6n+/e+q1dX718nOVj36aLdOzU9iouptt6muWHHg/rZsUe3WTbV7d9WtW93yyy9XFVEdNswtr65Wvfhi1bAwt3zHDtVRo1SDglR/8QvVzMwD97lzp+qQIW79t99WLStTffFF1SOOUA0JUf3kk7rP7amnXKxjxrjfb799aK9NTo7qa6+pzp6tWlKiqqrl5Vmal/eN7tz5on7zzSCdPRtdsGC47t0789D2bcxhDlio9XyuBvyD3R8/zU4W8+apRkerfvpp87ZvC5YtU01KUk1LU33uOdWf/1x1xAj3p3DjjaoVFapFRarHHus+qF99VXXaNNW//U31sstcGagOHeo+/O+8U/Woo1RjY1WXLz/wWDNnuvLOnVV/+Uu33e9+t395YaHqtde6pBIVpfrAA6p/+pPq6aerRkS4soOTQm6uSyIxMapLlhy4LCNDNS5O9ZRTVEtLVceOde/nmjWNvy5Ll6recINqp077k2NEhNvX11/vW626ulJ37Xpdv/qqr86ejS5deoYWFKxoYMfGtB2WLJqqqEh14ED3QZqd3bx9HE4qKlQfe0z1rrvct/Lp01WTk10NYMOG/etVVak++KD7czjzTNWJE903/rq+le/Zo/qXv6ieeqpq//6qkZEuIcyaVXcMq1er9u27/9t+RUXd61x66f4P6UGDVG+//YfJp8a2be496tpVdfPm/eWTJ6uGhu5PDlu3uvM98khX41i79sDaU1aWKx81an9yuPZa1fnzVWfMUL3jDvdaJSaqrlt3QAhVVWW6detfdN68eJ09O0iXLJmgq1dfrZu/vl0z1jynZWW7D4w5P1/1++/rPh9jDhOWLA7FggWumeOKK5q/j8NBebnqJZfs/xCs+SDu1k11/fq6t3nuOdXgYLfe88837TjV1XUngNr27lW9557GPyw3bnSJoClWrnS1iOho1dGjVS+6yMV9//0Hrjdnjmrv3vvPPynJJZBOnVyNBlxT2ZNP1t0EuWHD/oSzZ8/+8spK1awsLd+0Qjd/fI1u/lVfzR0ZrtWCVkSia+5Gv/1miK5YcaGue26wlnYO1upgtOKhexp/vYwJkIaShXVw1+Wxx+Chh+Bf/4IrrvBdYK2lvBwuuwymT4cnnoA774QtW2DdOhgxwnUw12fuXNi9Gy69tPXiba7Fi+GFF+D772HDBoiLgy++gKioA9dThY0b4dNPYdEiCAmBTp0gNhbOPde9Jg356it3NdaoUXD77fDuu/D++66Dvrb+/dHLL6NqzkxC5i4k74RkitOq6PJmDuU9Y8jrW0Tq7Gp03BjkjTehb1/fvh7GtJCNszhUlZXuyp61a2HFCkhL811wvrJgAfz+9+5KptRUd8VSWZn7AFu82F1BNGUK3HproCNtH/797/0JNDkZzjsPhgxxiSkyEgYNcklHBKqr4W9/gwcecO/JzTfDn/7E3pLPyPzbJAY8GUxQKcixx8JZZ8Gxx7r18vPd3156OvTpU/+VZ8b4iSWL5tiwwX0YTJoEU6f6JjBfKChwl6M+9ZS7lDUxETIz3WWmISHu23VCAtx/P1x3XaCjbV8+/RTCwmD8+PovN67tu+/c5cLjx+8r2r37dTZ9fhVHfHIEyQvCCFq+pu5tu3WDsWNdDQjc8UaMgBNOgGHD3HNVl2QiIuqPISMDfv5zKC6GG25wlyKH2A0yTd0sWTTX//0fPPIIzJkDJ57Y8v211PLlcPbZsGMH/OxnbuBZXJxbVlUFQUH2bbQN2LHj72zYcCeqlXSuOoXue4+nU+exhCR0cbWSr7+GefNcDbFmYGFJiRtnAq42ExQEhYUuYVx0ETzzjKtd1jZ/PlxyiRtTk5Tk/m66d4ff/AauuablJ5Kf75ryTLthyaK5SkrciOS4uP1t3YGycqVrN4+IcE0i48YFLhbTYmVlu9i581l27nyWiopMQOjUaRCxsaOJihpKVNQQoqOHEhZWa0qUbdtcEvnmG/elIDbWjXB/6imIj3f9N2PGuC8Vc+e6wYu9erlR84MHu36WP/7R9cF8/HH9AxsbU1LiaiuvvALvvedG5Jt2wZJFS/z3v+6b29//7r7NB8KaNXDSSS5ZzZkD/foFJg7jc1VVpeTmzqag4Fvy87+loGChlzycuLgT6dJlMikpFxMSEl33TlasgJ/85IfTp5x/Prz8skskNYqKXELJzHSj3A/uj8vMdBdELFjgaiunnHLg8o0b3f/D0qWuJhMa6r7IJCS04FUwhwtLFi2hCqed5poE1q931Xl/q6x03x7XrHFXML3+uvsmOWcODBjg/+ObgCovz6SoaAV5efPJyHidkpL1BAVFkZZ2Kz163EtoaB0fzOXlrmZRVQVDh7r+tvr+VteudVOiDBni/qbCwtzf+WuvwV13ueatbt1g82Z39ddjj7nE8r//uWMA/POfbgqWsWPhxz92tYwaW7ZAz57WJNoG2XQfLbVypRt7cf75Bw7q8rWqKtWpU1UHDNg/LiAsTDU9XXXVKv8d1xy2qqurNTf3S1216gqdPVt07tw43bz5MS0sXK3V1ZXN3/G0ae7va/hwN61LXJx7Pn68GyRZVKR6662urGbsTWio6llnufEwNR56yC2bMUN10SLV005zzx95pO7jZmW5EfFTpx44oNIcFrBBeT7w17+6l+v3v/f9vqurVf/3PzeFBqgOHqz6xhtuEFtlCz4QTLtSULBMly8/T2fPRmfPRj//PEIXLhytGzc+pEVFaw99h3/4g+rIkaqTJrlpX157zX1hqe3jj92yadNU8/J+uI+yMvd3WzNNSmKimyomKEj1iy/2r7d+/YFfgsANqHzhhbq/gJWWunhef923gxirq90Xr4PP06iqJQvfqK52cyMFBfl27qgvv3QT+YGbJO+NNyxBmAYVFq7RXbte1fXr79LFi4/X2bPFm9xwlG7c+GvNyvpYKyoKtKqqTIuLN2h29iwtLd3uv4CWLHGJ4Je/dHN35eW5KV569XITM65d62YOSE52c3+9+67qV1+pnnyy+7s/91w3ceNXX7kZFB591M0nVpNUhgzx3f/c00+7ff76177ZXzvTULKwPotDUVjorkLKyHAdh0cd5a42KSqC1atdH0NEhLsOfsAA1yFdXu46DfPyoLTU/WzZ4q5q+eIL1znYpQs8/LAbFxFqN9sxh6asbCeZmdPIzJxKQcECoBp3qxr1fiAoqBN9+/6W7t1/jkgTxoi01DffuPElp57qOt6rq939To4+ev861dVu4Oj997vxIrVNnOj6T3Jz3VTzmze7zvbLL3cDIqOiYNo0ePFFd0nxs8/CGWc0HNPixXDMMe5/rLTUXRU2enTTz0nVXULfs6frs2mHAtJnAfQAZgOrgVXA7V55IvAJsN77neCVCzAF2AAsB0bW2tfV3vrrgasbO7ZfahY11q1TTUjY/62npj334J/wcNX4+LqXgZs19YwzVP/8Zzf7qjE+UFGRp1lZH+nGjb/WjRsf1p07X9asrA912bKzdPZsdNGicZqdPUvLy1thoszHH3d/6126uH6Q+mzd6iainDnTTXa59qAmtZIS1/xbMyFlUND+Zq+BA92sxyKqDz/sauUrVrip9MeMcfOdVVS4Gk/fvm4CyvXr3e+BA1WLi5t+Pu+9t///d9myZr0khzsCUbMQka5AV1VdLCIxwCLgfGAykK2qvxeR+71kcZ+InAXcCpwFjAX+pqpjRSQRWAik474mLQJGqWpOfcf2+82PcnPd5Yrr17uR3rGx7jr2QYPcSNnly923qeJiNw9Taqq7tDAiwv107uy+YTVlFLAxPqCqZGb+i/Xrb6eyMguAsLBuxMUdR7duNxMff6Lv7z1eVQVPP+2mNDniiJbvT9X9b/33v25k/JVXuqlSSkrclCqvveYGHe7Y4a7wOuIIV9sfMAC6dnW1+c8/dzWeTz6B0093lwk/8AB89BF89pmrcUREuJrLDTe4K8tqjj1unJs3LSfH1WL+/e+Wn9Nh5rC4Ggp4FzgNWIdLIgBdgXXe4+eAK2qtv85bfgXwXK3yA9ar68evNQtj2rDy8hzdu/cD3bLlj7p69Y913rwEnT0b/eabwbpjx3NaVVUa6BCbp7razZR88smutr5njyubPt1NeQ+qf/zjgdv87GeuvGb24aQkN7twWpqber9zZ1frUVX96CO3znPP7b83y8E3AWsHCHSfhYj0BuYCRwNbVTXeKxcgR1XjReQ94Peq+oW3bBZwH3ASEKGqj3nlDwElqvrEQce4EbgRoGfPnqO2bNni9/Mypq2rqiomM3MqO3Y8RWHhEsLDe9Cz5wN07XotQUHhgQ7PN6qqXEvAsGEHjv0oKoLbbnN9EGed5WYVDvJulbtmjRtD0r+/q5GceqobQb9+veu77N3bTb0zdaqrdXz4oeunCQ11tZpu3dyMxjXToaxb5+Z0mz/f1YAOHuzYXN9+C7/9rasl+WDQcEBrFkA0runoQu957kHLc7zf7wHH1SqfhWt6uhv4Va3yh4C7Gzqm1SyMOTTV1dWalfWxLlp0rM6ejc6bl6jLlk30rq76qGVjOtqqGTNcraPmFr1PPbV/2QMPuGX//KfqCSfU3S8ZEeHuKXPtta5vMzra9ZsEB6tOmdL4mK1Nm9ztib/88ofL1qxRveAC3Tf+BdxlyC1EoC6dBUKBj4C7apVZM5Qxh6mapLFmzTX67bdH6+zZQTp7Njp/fg/dtOlRLS7epBUV+VpZWaLV1R1grEJNJ33Xrvvuya6qrpkrKsotS0lx97AvK3M3HSssdHdb/PnP3bLQUNfhnpHh7ph43nluu4suUr3uOnehy3HHubEsNQlk4cL9lw9HRblbPtd48UU3WDcmxl1mnJXl7nAZFKT673+36HQDkixwVze9Bjx5UPmfgPu9x/cDf/Qenw3M9LYbB3zrlScCm4AE72cTkNjQsS1ZGOMbFRUFmpn5ti5detq+wYC1BwWuXftTLS7e0PiO2qrqaveBPHPmD5e9+abqb3/rEkB9yst/uLyqyvV7hIe7K8XS090tisHVUp55xiWInj3d+JIBA9zzWbP297OcdppLPjWKitzo+9BQ1Q8/bPbpNpQs/Hk11HHAPGAF7sJvgAeBb4BpQE9gC3CpqmZ7/RdPAWcCxcA1qrrQ29e13rYAj6vqyw0d2+9XQxnTARUXbyA7+0Oqq0tRraCkZAMZGf9EtZLk5AuIjOyDSAgiIQQFRREcHE1ISBxJSecSGhrf+AE6GtX9fShVVW7MyK9+BXv3wvDhbpbgbt1g1y44+WQ3pxfA3XfD7373w1mwc3PdzNRHHeXu8tkMNpGgMcYvysp2sX37X9m9+1WqqgpRrUS1gprBgAAREX0ZPPg/xMQMD1ygbUVuLrzzjpvZt/a9QjIyXAf2xRc3fKvn7GyIiWn24F5LFsaYVqOqVFeXUlVVSFHRctasuYrKymz693+WLl2uDnR4pgGWLIwxAVNensHq1ZeTmzuHsLAuhIenER6eRlTUUOLijicu7hiCg6MCHaah4WRhN+M1xvhVWFhnhg79hJ07n6WwcCllZdspLl7H3r0zcN2ZwcTEjCA2dhyxsccQH38S4eHdAh22OYglC2OM3wUFhZCW9vMDyior88jLm09e3jzy879i165/sGPHUwDExh5LSsqFJCScSkREX0JCYgIRtqnFkoUxJiDclVITSUpy9/Curq6kqGgFWVnvs3fvf/j++7trrZtETMwIOnf+McnJF9V/i1njN9ZnYYw5LJWUbKSgYBGlpRspKdlITs4sSku/JyioE8nJk0hMPIOEhFMJD+8e6FDbDeuzMMa0OZGRfYmM7LvvuaqSnz+f3btfYe/ed8nMfBOATp0GkZg4kaSks4iLO46goLBAhdyuWc3CGNPmqFZTVLSC7OxPyMn5iNzcuaiWA0HewMBgREIJC0slNLQzERE9SE39EUlJZ7XOzZ/aKLt01hjTrlVWFpKb+xkFBQuorq4AqqmuLqOiIpPy8gyKi9dQXr6biIi+dOlyDRUVeykoWEBx8Vq6dJlM376/bT+z7LaAJQtjTIdWXV3J3r3T2bFjCnl58wgKiiQmZhShoSns3fsOUVFDGTToX0RFDQ50qAFlfRbGmA4tKCiE1NSLSU29mLKy3YSGJhMU5D7+srLeZ+3aa1m0KJ3k5IuIjz+R+PgTiYzs5/u7B7ZhliyMMR1KeHiXA54nJZ3N6NHL+f77+8jOnklm5htAzeW6I4mJGUWnTgMJD+9FREQvIiJ6dsh+D0sWxpgOLyysM0cd9QqqSnHxOvLy5lJQsICCgkVs2/Znb3JEJzg4lvj4E4iPn0Bs7DgiI/sRGprc7mshliyMMcYjIkRFDSQqaiDeXZqpri6ntHQrZWVbKC3dTH7+t+TmziYr67192wUHxxEdPYzExDNITDyT6OjhiAQF6Cz8wzq4jTGmGUpLt1NUtIzi4vWUlKwnP/9rCgsXAxAamkJCwukkJp5BfPyJhId3bxNNV9bBbYwxPhYRkUZERBpJSfvLysszyM7+mOzsj8jJ+Whf/wcEERbWhYiIXkRFDSYqagjR0cOJjR3XZgYRWs3CGGP8QLWawsIl5OcvoLx8B2Vl2ykp2URR0UoqK7MACA6OJj7+FBITTyM8vCehoSmEhaUSFtaN4OCIVo/ZahbGGNPKRIKIiRlFTMyoA8pVlfLy3RQUfEt29odkZc0kK+vdH2zvRp73Ijp6GLGxY4mOHkV1dRElJZsoK9tKVNTRJCae0WqDCa1mYYwxAaSqlJVtp7x8NxUVeygvz6CsbDtlZVspKdlIYeFiKitz69w2ODiOlJQLSEg4g5iYdCIjj2jRVVlWszDGmMOUiBAR0YOIiB51LletpqRkA4WFSwgOjiUiog/h4d3Jy/uSzMyp7NnzX3bvfgWAkJB4unS5liOP/LPP47RkYYwxhzGRIDp16k+nTv0PKE9KOpOkpDOprn6BoqJV3riQhURE9PRLHJYsjDGmDQsKCiUmZjgxMcOBG/x3HL/t2RhjTLthycIYY0yjLFkYY4xplCULY4wxjbJkYYwxplGWLIwxxjTKkoUxxphGWbIwxhjTqHY5N5SI7AG2HMImycBeP4VzOOuI590Rzxk65nl3xHOGlp13L1VNqWtBu0wWh0pEFtY3eVZ71hHPuyOeM3TM8+6I5wz+O29rhjLGGNMoSxbGGGMaZcnCeT7QAQRIRzzvjnjO0DHPuyOeM/jpvK3PwhhjTKOsZmGMMaZRliyMMcY0qsMnCxE5U0TWicgGEbk/0PH4g4j0EJHZIrJaRFaJyO1eeaKIfCIi673fCYGO1R9EJFhElojIe97zPiLyjfeevyUiYYGO0ZdEJF5E3haRtSKyRkSO6QjvtYjc6f19rxSRN0Ukoj2+1yLyDxHJFJGVtcrqfH/FmeKd/3IRGdnc43boZCEiwcDfgYnAIOAKERkU2Kj8ohL4haoOAsYBt3jneT8wS1X7AbO85+3R7cCaWs//APxVVY8EcoDrAhKV//wN+FBVBwLDcOfert9rEekO3Aakq+rRQDBwOe3zvX4FOPOgsvre34lAP+/nRuCZ5h60QycLYAywQVU3qmo5MBWYFOCYfE5Vd6nqYu9xAe7DozvuXF/1VnsVOD8wEfqPiKQBZwMves8FOBl421ulXZ23iMQBJwAvAahquarm0gHea9xtoiNFJAToBOyiHb7XqjoXyD6ouL73dxLwmjpfA/Ei0rU5x+3oyaI7sK3W8+1eWbslIr2BEcA3QGdV3eUt2g10DlBY/vQkcC9Q7T1PAnJVtdJ73t7e8z7AHuBlr+ntRRGJop2/16q6A3gC2IpLEnnAItr3e11bfe+vzz7jOnqy6FBEJBr4D3CHqubXXqbuGup2dR21iJwDZKrqokDH0opCgJHAM6o6AijioCandvpeJ+C+RfcBugFR/LCppkPw1/vb0ZPFDqBHredpXlm7IyKhuETxhqr+1yvOqKmSer8zAxWfn4wHzhORzbgmxpNx7fnxXlMFtL/3fDuwXVW/8Z6/jUse7f29PhXYpKp7VLUC+C/u/W/P73Vt9b2/PvuM6+jJYgHQz7tiIgzXITYjwDH5nNdO/xKwRlX/UmvRDOBq7/HVwLutHZs/qeoDqpqmqr1x7+1nqnolMBu42FutXZ23qu4GtonIAK/oFGA17fy9xjU/jRORTt7fe815t9v3+iD1vb8zgKu8q6LGAXm1mqsOSYcfwS0iZ+HatYOBf6jq4wEOyedE5DhgHrCC/W33D+L6LaYBPXFTul+qqgd3nLULInIScLeqniMifXE1jURgCfBjVS0LZHy+JCLDcR36YcBG4BrcF8N2/V6LyP8Bl+Gu/lsCXI9rn29X77WIvAmchJuKPAN4GJhOHe+vlzifwjXJFQPXqOrCZh23oycLY4wxjevozVDGGGOawJKFMcaYRlmyMMYY0yhLFsYYYxplycIYY0yjLFkYcwhEpEpEltb68dmEfCLSu/ZMosYcTkIaX8UYU0uJqg4PdBDGtDarWRjjAyKyWUT+KCIrRORbETnSK+8tIp959xKYJSI9vfLOIvKOiCzzfo71dhUsIi9492X4WEQivfVvE3c/kuUiMjVAp2k6MEsWxhyayIOaoS6rtSxPVYfgRsw+6ZX9P+BVVR0KvAFM8cqnAJ+r6jDc3E2rvPJ+wN9VdTCQC1zkld8PjPD2c5O/Ts6Y+tgIbmMOgYgUqmp0HeWbgZNVdaM3aeNuVU0Skb1AV1Wt8Mp3qWqyiOwB0mpPPeFNH/+JdwMbROQ+IFRVHxORD4FC3LQO01W10M+naswBrGZhjO9oPY8PRe15i6rY3694Nu6ujiOBBbVmUjWmVViyMMZ3Lqv1+yvv8XzcjLcAV+ImdAR368ubYd89wuPq26mIBAE9VHU2cB8QB/ygdmOMP9m3E2MOTaSILK31/ENVrbl8NkFEluNqB1d4Zbfi7lp3D+4Odtd45bcDz4vIdbgaxM24O7zVJRj4p5dQBJji3SrVmFZjfRbG+IDXZ5GuqnsDHYsx/mDNUMYYYxplNQtjjDGNspqFMcaYRlmyMMYY0yhLFsYYYxplycIYY0yjLFkYY4xp1P8HIV0ZQR3Zui0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='MeanSquaredError', metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, verbose=0)\n",
        "\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_scaled, y_test, verbose=0)"
      ],
      "metadata": {
        "id": "k-GvWPEst1Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxpTAPmnuRZD",
        "outputId": "d5db03ff-e301-4379-bb5b-b19d3b1d954f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9612600803375244"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uu7NcQnvZ0E",
        "outputId": "5523d1c0-cc7a-48be-f570-9d1f710baabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9460237622261047"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2ifoJTYvesj",
        "outputId": "8618d7fc-5fc2-4d77-8da1-554074e1f2bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9784834384918213"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rRk8TGxQiaoi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}